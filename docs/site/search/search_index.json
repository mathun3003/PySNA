{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PySNA Documentation Contents for users: Installation Quick Start User Guide TwitterAPI Utility Functions CLI Tool Contents for maintainers: Implementation Details TwitterAPI TwitterDataFetcher TwitterDataProcessor BaseDataProcessor Utility Functions CLI Functions Software Tests Repository Information Links: Tweepy Docs Twitter API Docs","title":"Home"},{"location":"#pysna-documentation","text":"Contents for users: Installation Quick Start User Guide TwitterAPI Utility Functions CLI Tool Contents for maintainers: Implementation Details TwitterAPI TwitterDataFetcher TwitterDataProcessor BaseDataProcessor Utility Functions CLI Functions Software Tests Repository Information Links: Tweepy Docs Twitter API Docs","title":"PySNA Documentation"},{"location":"maintenance/BaseDataProcessor/","text":"BaseDataProcessor The BaseDataProcessor class contains general operations for data processing. It forms the basis for the TwitterDataProcessor class. The BaseDataProcessor class is used within the TwitterAPI class for processing data that is not specific to any social media platform. Methods exist for calculating descriptive metrics for numeric and datetime values as well as calculating the intersection and difference of sets. This class can also be used to process previously collected data. Initialization If you want to use this class for data processing or other package components, follow the steps below. Import the BaseDataProcessor class from the process module: from pysna.process import BaseDataProcessor # init instance data_processor = BaseDataProcessor() and start invoking a function: sets = [set(1,2,4), set(1,3,5), set(1,8,9)] # calculate intersection of all sets data_processor.intersection(sets) Methods The methods of this class use functions from Numpy and default Python operations. calc_descriptive_metrics Calculates descriptive metrics of a given data set. Returns the given data set with appended statistical metrics. Input data set must be a dictionary containing numeric values. Function: BaseDataProcessor.calc_descriptive_metrics(data: Dict[str | int, Number]) The following metrics are calculated: Max Value Min Value Mean Value Median Standard Deviation Sample Variance Range (Max - Min) Interquartiles Range Mean Absolute Deviation These metrics might help to interpret the data more accurately and saves time to evaluate data manually. All metrics are calculated and appended to a new key 'metrics' in the input dictionary. This implementation enables to enrich input data with statistical metrics without the need to append the metrics to the dictionary after calculation. Source Code import numpy as np def calc_descriptive_metrics(self, data: Dict[str | int, Number]) -> dict: \"\"\"Calculates descriptive metrics of a given data set. Args: data (Dict[str | int, Number]): Data dictionary containing numeric values. Raises: ValueError: If non-numeric values are contained in the data dictionary. Returns: dict: Input data dictionary containing descriptive metrics. Metrics: - Max Value - Min Value - Mean Value - Median - Standard Deviation - Sample Variance - Range (Max - Min) - Interquartiles Range - Mean Absolute Deviation \"\"\" if not any(isinstance(value, Number) for value in data.values()): raise ValueError(\"Only numeric values are allowed.\") # extract numeric values by iterating over data dict with iterable items numerics = list(data.values()) # init empty dict to store descriptive metrics metrics = dict() # calc max metrics[\"max\"] = max(numerics) # calc min metrics[\"min\"] = min(numerics) # calc mean metrics[\"mean\"] = np.array(numerics).mean() # calc median metrics[\"median\"] = np.median(numerics) # calc standard deviation metrics[\"std\"] = np.std(numerics) # calc variance metrics[\"var\"] = np.var(numerics) # calc range metrics[\"range\"] = max(numerics) - min(numerics) # calc interquarile range metrics[\"IQR\"] = np.subtract(*np.percentile(numerics, [75, 25])) # calc absolute mean deviation metrics[\"mad\"] = np.mean(np.absolute(numerics - np.mean(numerics))) # add metrics data[\"metrics\"] = metrics return data calc_datetime_metrics Calculates descriptive metrics on datetime objects. The function takes in a dictionary with datetime values. The function will return the input dictionary with appended metrics. Function: BaseDataProcessor.calc_datetime_metrics(dates: Dict[str, datetime]) The following metrics are calculated: Mean Median Max Min Time Span (in days, seconds, and microseconds) Deviation from mean (in days and seconds). Negative values indicate below average, positive ones above average. Deviation from median (in days and seconds). Negative values indicate below median, positive ones above average. The metrics will help to analyze creation dates of social media accounts or posts. The metrics are choosed based on typical behaviors of social bots as they are often created within a short period. These metrics will help to figure out if it is likely that the investigated account is a social bot. All metrics are calculated and appended to a new key 'metrics' in the input dictionary. This implementation enables to enrich input data with statistical metrics without the need to append the metrics to the dictionary after calculation. Source Code def calc_datetime_metrics(self, dates: Dict[str, datetime]) -> dict(): \"\"\"Calculates descriptive metrics on datetime objects. Args: dates (Dict[str, datetime]): Dictionary containing identifiers as keys and datetime objects as values. Returns: dict: Input dates with added datetime metrics. Metrics: - Mean - Median - Max - Min - Time Span (in days, seconds, and microseconds) - Deviation from mean (in days and seconds). Negative values indicate below average, positive ones above average. - Deviation from median (in days and seconds). Negative values indicate below median, positive ones above average. \"\"\" # use the datetime's timestamp to make them comparable timestamps = [dt.timestamp() for dt in dates.values()] # calc mean of creation dates total_time = sum(timestamps) mean_timestamp = total_time / len(timestamps) # convert mean timestamp back to datetime object with timezone information mean_datetime = datetime.fromtimestamp(mean_timestamp, tz=timezone.utc) # calculate time differences to mean datetime of every creation date time_diffs_mean = {key: {\"days\": (dt - mean_datetime).days, \"seconds\": (dt - mean_datetime).seconds} for key, dt in dates.items()} # find the median of the timestamps median_timestamp = np.median(timestamps) # Convert median timestamp back to datetime object median_datetime = datetime.fromtimestamp(median_timestamp, tz=timezone.utc) # calculate time differences to median timestamp of every creation date time_diffs_median = {key: {\"days\": (dt - median_datetime).days, \"seconds\": (dt - median_datetime).seconds} for key, dt in dates.items()} # calc range of creation dates max_date, min_date = max(dates.values()), min(dates.values()) time_span = max_date - min_date # convert creation dates to isoformat for readability dates = {key: dt.isoformat() for key, dt in dates.items()} # add metrics to output dates[\"metrics\"] = dict() dates[\"metrics\"][\"deviation_from_mean\"] = time_diffs_mean dates[\"metrics\"][\"deviation_from_median\"] = time_diffs_median dates[\"metrics\"][\"time_span\"] = {\"days\": time_span.days, \"seconds\": time_span.seconds, \"microseconds\": time_span.microseconds} dates[\"metrics\"][\"mean\"] = mean_datetime.isoformat() dates[\"metrics\"][\"median\"] = median_datetime.isoformat() dates[\"metrics\"][\"max\"] = max_date.isoformat() dates[\"metrics\"][\"min\"] = min_date.isoformat() return dates intersection Calculates the intersection of multiple sets. This function takes in a list of sets and returns their intersection. Function: BaseDataProcessor.intersection(iterable: List[set]) This function is used, for example, to get the follower IDs of multiple social media accounts. The sets contain the individual follower IDs of the social media accounts. Source Code def intersection(self, iterable: List[set]) -> list: \"\"\"Calculates the intersection of multiple sets. Args: iterable (List[set]): List containing sets. Returns: list: intersection set casted to list. \"\"\" intersection = set.intersection(*map(set, iterable)) return list(intersection) difference Calculates the difference of multiple sets. The function takes in a list of dictionaries containing identifiers (e.g., account IDs) as keys and the sets as values. This function will return for each key in the dictionary the individual difference of each set. Function: BaseDataProcessor.difference(sets: Dict[int | str, set]) This function is used to calculate the difference of followers of the specified social media accounts. In this context, the account IDs are stored as dictionary keys and their follower IDs as values. Source Code def difference(self, sets: Dict[int | str, set]) -> dict: \"\"\"Calculates the difference of multiple sets. Args: sets (Dict[set]): Dictionary containing sets where keys are identifiers. Returns: dict: Individual difference of each set that was provided. \"\"\" # init empty dict to store individual differences for each set differences = dict() for key, values in sets.items(): differences[key] = list(set(values)) for other_key, other_values in sets.items(): if key != other_key: differences[key] = list(set(differences[key]) - set(other_values)) return differences","title":"BaseDataProcessor"},{"location":"maintenance/BaseDataProcessor/#basedataprocessor","text":"The BaseDataProcessor class contains general operations for data processing. It forms the basis for the TwitterDataProcessor class. The BaseDataProcessor class is used within the TwitterAPI class for processing data that is not specific to any social media platform. Methods exist for calculating descriptive metrics for numeric and datetime values as well as calculating the intersection and difference of sets. This class can also be used to process previously collected data.","title":"BaseDataProcessor"},{"location":"maintenance/BaseDataProcessor/#initialization","text":"If you want to use this class for data processing or other package components, follow the steps below. Import the BaseDataProcessor class from the process module: from pysna.process import BaseDataProcessor # init instance data_processor = BaseDataProcessor() and start invoking a function: sets = [set(1,2,4), set(1,3,5), set(1,8,9)] # calculate intersection of all sets data_processor.intersection(sets)","title":"Initialization"},{"location":"maintenance/BaseDataProcessor/#methods","text":"The methods of this class use functions from Numpy and default Python operations.","title":"Methods"},{"location":"maintenance/BaseDataProcessor/#calc_descriptive_metrics","text":"Calculates descriptive metrics of a given data set. Returns the given data set with appended statistical metrics. Input data set must be a dictionary containing numeric values. Function: BaseDataProcessor.calc_descriptive_metrics(data: Dict[str | int, Number]) The following metrics are calculated: Max Value Min Value Mean Value Median Standard Deviation Sample Variance Range (Max - Min) Interquartiles Range Mean Absolute Deviation These metrics might help to interpret the data more accurately and saves time to evaluate data manually. All metrics are calculated and appended to a new key 'metrics' in the input dictionary. This implementation enables to enrich input data with statistical metrics without the need to append the metrics to the dictionary after calculation. Source Code import numpy as np def calc_descriptive_metrics(self, data: Dict[str | int, Number]) -> dict: \"\"\"Calculates descriptive metrics of a given data set. Args: data (Dict[str | int, Number]): Data dictionary containing numeric values. Raises: ValueError: If non-numeric values are contained in the data dictionary. Returns: dict: Input data dictionary containing descriptive metrics. Metrics: - Max Value - Min Value - Mean Value - Median - Standard Deviation - Sample Variance - Range (Max - Min) - Interquartiles Range - Mean Absolute Deviation \"\"\" if not any(isinstance(value, Number) for value in data.values()): raise ValueError(\"Only numeric values are allowed.\") # extract numeric values by iterating over data dict with iterable items numerics = list(data.values()) # init empty dict to store descriptive metrics metrics = dict() # calc max metrics[\"max\"] = max(numerics) # calc min metrics[\"min\"] = min(numerics) # calc mean metrics[\"mean\"] = np.array(numerics).mean() # calc median metrics[\"median\"] = np.median(numerics) # calc standard deviation metrics[\"std\"] = np.std(numerics) # calc variance metrics[\"var\"] = np.var(numerics) # calc range metrics[\"range\"] = max(numerics) - min(numerics) # calc interquarile range metrics[\"IQR\"] = np.subtract(*np.percentile(numerics, [75, 25])) # calc absolute mean deviation metrics[\"mad\"] = np.mean(np.absolute(numerics - np.mean(numerics))) # add metrics data[\"metrics\"] = metrics return data","title":"calc_descriptive_metrics"},{"location":"maintenance/BaseDataProcessor/#calc_datetime_metrics","text":"Calculates descriptive metrics on datetime objects. The function takes in a dictionary with datetime values. The function will return the input dictionary with appended metrics. Function: BaseDataProcessor.calc_datetime_metrics(dates: Dict[str, datetime]) The following metrics are calculated: Mean Median Max Min Time Span (in days, seconds, and microseconds) Deviation from mean (in days and seconds). Negative values indicate below average, positive ones above average. Deviation from median (in days and seconds). Negative values indicate below median, positive ones above average. The metrics will help to analyze creation dates of social media accounts or posts. The metrics are choosed based on typical behaviors of social bots as they are often created within a short period. These metrics will help to figure out if it is likely that the investigated account is a social bot. All metrics are calculated and appended to a new key 'metrics' in the input dictionary. This implementation enables to enrich input data with statistical metrics without the need to append the metrics to the dictionary after calculation. Source Code def calc_datetime_metrics(self, dates: Dict[str, datetime]) -> dict(): \"\"\"Calculates descriptive metrics on datetime objects. Args: dates (Dict[str, datetime]): Dictionary containing identifiers as keys and datetime objects as values. Returns: dict: Input dates with added datetime metrics. Metrics: - Mean - Median - Max - Min - Time Span (in days, seconds, and microseconds) - Deviation from mean (in days and seconds). Negative values indicate below average, positive ones above average. - Deviation from median (in days and seconds). Negative values indicate below median, positive ones above average. \"\"\" # use the datetime's timestamp to make them comparable timestamps = [dt.timestamp() for dt in dates.values()] # calc mean of creation dates total_time = sum(timestamps) mean_timestamp = total_time / len(timestamps) # convert mean timestamp back to datetime object with timezone information mean_datetime = datetime.fromtimestamp(mean_timestamp, tz=timezone.utc) # calculate time differences to mean datetime of every creation date time_diffs_mean = {key: {\"days\": (dt - mean_datetime).days, \"seconds\": (dt - mean_datetime).seconds} for key, dt in dates.items()} # find the median of the timestamps median_timestamp = np.median(timestamps) # Convert median timestamp back to datetime object median_datetime = datetime.fromtimestamp(median_timestamp, tz=timezone.utc) # calculate time differences to median timestamp of every creation date time_diffs_median = {key: {\"days\": (dt - median_datetime).days, \"seconds\": (dt - median_datetime).seconds} for key, dt in dates.items()} # calc range of creation dates max_date, min_date = max(dates.values()), min(dates.values()) time_span = max_date - min_date # convert creation dates to isoformat for readability dates = {key: dt.isoformat() for key, dt in dates.items()} # add metrics to output dates[\"metrics\"] = dict() dates[\"metrics\"][\"deviation_from_mean\"] = time_diffs_mean dates[\"metrics\"][\"deviation_from_median\"] = time_diffs_median dates[\"metrics\"][\"time_span\"] = {\"days\": time_span.days, \"seconds\": time_span.seconds, \"microseconds\": time_span.microseconds} dates[\"metrics\"][\"mean\"] = mean_datetime.isoformat() dates[\"metrics\"][\"median\"] = median_datetime.isoformat() dates[\"metrics\"][\"max\"] = max_date.isoformat() dates[\"metrics\"][\"min\"] = min_date.isoformat() return dates","title":"calc_datetime_metrics"},{"location":"maintenance/BaseDataProcessor/#intersection","text":"Calculates the intersection of multiple sets. This function takes in a list of sets and returns their intersection. Function: BaseDataProcessor.intersection(iterable: List[set]) This function is used, for example, to get the follower IDs of multiple social media accounts. The sets contain the individual follower IDs of the social media accounts. Source Code def intersection(self, iterable: List[set]) -> list: \"\"\"Calculates the intersection of multiple sets. Args: iterable (List[set]): List containing sets. Returns: list: intersection set casted to list. \"\"\" intersection = set.intersection(*map(set, iterable)) return list(intersection)","title":"intersection"},{"location":"maintenance/BaseDataProcessor/#difference","text":"Calculates the difference of multiple sets. The function takes in a list of dictionaries containing identifiers (e.g., account IDs) as keys and the sets as values. This function will return for each key in the dictionary the individual difference of each set. Function: BaseDataProcessor.difference(sets: Dict[int | str, set]) This function is used to calculate the difference of followers of the specified social media accounts. In this context, the account IDs are stored as dictionary keys and their follower IDs as values. Source Code def difference(self, sets: Dict[int | str, set]) -> dict: \"\"\"Calculates the difference of multiple sets. Args: sets (Dict[set]): Dictionary containing sets where keys are identifiers. Returns: dict: Individual difference of each set that was provided. \"\"\" # init empty dict to store individual differences for each set differences = dict() for key, values in sets.items(): differences[key] = list(set(values)) for other_key, other_values in sets.items(): if key != other_key: differences[key] = list(set(differences[key]) - set(other_values)) return differences","title":"difference"},{"location":"maintenance/TwitterAPI/","text":"TwitterAPI The TwitterAPI class forms the main class for user interaction and serves as a simple interface through encapsulation since the user can use all the functionalities of the package via the four main functions. All functionalities (except the utility function from the utils module) can be used via this class. The TwitterAPI class combines compatible data processing mechanisms with the respective data queries. This is achieved through composition whereby instances of the TwitterDataFetcher and TwitterDataProcessor are created within the class\u2019s constructor. Data processing mechanisms are outsourced to the functions of the TwitterDataProcessor instance whereas the data querying mechanisms are outsourced to the TwitterDataFetcher instance. This design decision ensures hiding implementation details from users or developers during usage or implementation and makes the code more structured. Thus, whenever any developer wants to make adjustments/fixes to the code, he or she has not to be aware of the code from the TwitterDataProcessor and TwitterDataFetcher instances. Contributing developers are able to understand this class's implementation by understanding the seperation of classes' concerns. This class serves the purpose of handling the input and output of user interactions through an interface. No further data processing or fetching is performed by this class. This class is built on top of the tweepy.Client class. The TwitterAPI class inherits the tweepy.Client class. Thus, every function from the inherited class will also be available in the TwitterAPI class, resulting in an package that extends the official Twitter API. The default behavior of the tweepy.Client class is overwritten but retained in order to extend this class. See the package architecture on the overview section of this chapter . Initialization Import the TwitterAPI class from the api module or use the shortcut. from pysna.api import TwitterAPI # full path from pysna import TwitterAPI # shortcut api = TwitterAPI( bearer_token: Any | None = None, consumer_key: Any | None = None, consumer_secret: Any | None = None, access_token: Any | None = None, access_token_secret: Any | None = None, x_rapidapi_key: Any | None = None, x_rapidapi_host: Any | None = None, wait_on_rate_limit: bool = True ) and invoke a function: user_id = 123450897612 api.user_info(user_id, [\"screen_name\", \"followers_count\"]) Find the necessary secrets on the user guide instructions . Methods All functions have pre-defined input parameters (either for the attributes or compare arguments). They are stored inside the literal objects: TwitterAPI.LITERALS_USER_INFO : available attributes for a Twitter account. For more information, see here . TwitterAPI.LITERALS_COMPARE_USERS : available comparison attributes for Twitter accounts. For more information, see here . TwitterAPI.LITERALS_TWEET_INFO : available attributes for a tweet. For more information, see here . TwitterAPI.LITERALS_COMPARE_TWEETS : available comparison attributes for tweets. For more information, see here . Each (comparison) attribute is covered in the corresponding main function by iterations of a for loop. Whenever one of the four main functions is called, the required data resources are fetched by making API calls via the TwitterDataFetcher class for each specified (comparison) attribute and are processed by the TwitterDataProcessor class if necessary. For instance, when comparing multiple users on their common followers, individual followers for each user are fetched first and then processed by calculating the intersection set of all individual followers. If any new functionality is added to this class (e.g., get the length of a tweet by a length attribute), the new attribute has to be added to the corresponding literal object. In addition, the comparison functions also have a features argument which is used to define a feature vector for comparison. The available similarity features for users and tweets are also specified in separate literal objects: TwitterAPI.SIMILARITY_FEATURES_COMPARE_USERS : available similarity features for the TwitterAPI.compare_users function. For more information, see here . TwitterAPI.SIMILARITY_FEATURES_COMPARE_TWEETS : available similarity features for the TwitterAPI.compare_tweets function. For more information, see here . handle_output (private) This function is designed to handle the output of the four main functions accordingly. To avoid accessing a returned dictionary with only one available key, this function returns either the single value from the one-key dictionary or the full dictionary itself if multiple keys are available. Function: TwitterAPI._handle_output(output: dict) This function is private and, thus, not intended for external use. This function was designed to facilitate the use of the package without the need for accessing a returned one-key dictionary. user_info This function allows to request user information from a Twitter account. Function: TwitterAPI.user_info(user: str | int, attributes: List[LITERALS_USER_INFO] | str, return_timestamp: bool = False) Args: user (str | int): Twitter User either specified by corresponding ID or screen name. attributes (List[str] | str): Attributes of the User object. These must be from this list . return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. This function takes in a Twitter user identifier (i.e., an ID or unique screen name). The attributes are passed in by a list object or by a single string. For a single provided attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. If the requested attribute for the objet is not available, None will be returned. Source Code def user_info(self, user: str | int, attributes: List[LITERALS_USER_INFO] | str, return_timestamp: bool = False) -> Any: \"\"\"Receive requested user information from Twitter User Object. For one attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Args: user (str | int): Twitter User either specified by corresponding ID or screen name. attributes (List[str] | str): Attributes of the User object. These must be from: id, id_str, name, screen_name, followers, followees, location, description, url, entities, protected, followers_count, friends_count, listed_count, created_at, latest_activity, last_active, liked_tweets, composed_tweets, favourites_count, verified, statuses_count, status, contributors_enabled, profile_image_url_https, profile_banner_url, default_profile, default_profile_image, withheld_in_countries, bot_scores return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. Raises: KeyError: If invalid attribute was provided. ValueError: If Botometer secrets were not provided. Returns: dict: Requested user information. References: https://mathun3003.github.io/PySNA/user-guide/overview/TwitterAPI/#user_info \"\"\" # catch Botometer API secrets before iteration over attributes. if \"bot_scores\" in attributes: if (self._x_rapidapi_key is None) or (self._x_rapidapi_host is None): raise ValueError(\"'X_RAPIDAPI_KEY' and 'X_RAPIDAPI_HOST' secrets for Botometer API need to be provided.\") # initialize empty dict to store requested attributes user_info = dict() # if single string was provided if isinstance(attributes, str): # convert to list for iteration attributes = [attributes] # get user object user_obj = self.fetcher.get_user_object(user) # loop through the list of attributes and add them to the dictionary for attr in attributes: # if invalid attribute was provided if attr not in get_args(self.LITERALS_USER_INFO): raise ValueError(\"Invalid attribute for '{}'\".format(attr)) # if the desired attribute is in default user object returned by the v1 Search API elif attr in user_obj._json.keys(): user_info[attr] = user_obj._json[attr] # get information about user's followers elif attr == \"followers\": user_info[attr] = self.data_processor.extract_followers(user_obj) # get information about user's followees elif attr == \"followees\": user_info[attr] = self.data_processor.extract_followees(user_obj) # get all liked tweets of user elif attr == \"liked_tweets\": # get page results first liked_tweets = self.fetcher.get_liked_tweets_ids(user) user_info[attr] = liked_tweets # get all composed tweets elif attr == \"composed_tweets\": # get page results first composed_tweets = self.fetcher.get_composed_tweets_ids(user) user_info[attr] = composed_tweets # get user's latest activity elif attr == \"latest_activity\": user_info[attr] = self.fetcher.get_latest_activity(user) # get user's latest activity date elif attr == \"last_active\": user_info[attr] = self.fetcher.get_latest_activity_date(user) # get user's botometer scores elif attr == \"bot_scores\": user_info[attr] = self.fetcher.get_botometer_scores(user) # if attribute was not found else: user_info[attr] = None # if timestamp should be returned if return_timestamp: user_info[\"utc_timestamp\"] = strf_datetime(datetime.utcnow(), format=\"%Y-%m-%d %H:%M:%S.%f\") return self._handle_output(user_info) compare_users This function allows a comparison of multiple Twitter accounts. Function: TwitterAPI.compare_users(users: List[str | int], compare: str | List[LITERALS_COMPARE_USERS], return_timestamp: bool = False, features: List[str] | None = None) Args: users (List[str | int]): User IDs or screen names compare (str): Comparison attribute. Must be from this list . return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. features (List[str] | None, optional): Defined features of Twitter User Object on which similarity will be computed. Must be from the features list . Defaults to None. This function takes in multiple Twitter user identifiers (i.e., IDs or unique screen names). The comparison attributes are passed in by a list object or by a single string. For a single attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Source Code def compare_users(self, users: List[str | int], compare: str | List[LITERALS_COMPARE_USERS], return_timestamp: bool = False, features: List[str] | None = None) -> Any: \"\"\"Compare two or more users with the specified comparison attribute(s). For one attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Args: users (List[str | int]): User IDs or screen names compare (str): Comparison attribute. Must be from: relationship, followers_count, followees_count, tweets_count, favourites_count, common_followers, distinct_followers, common_followees, distinct_followees, commonly_liked_tweets, distinctly_liked_tweets, similarity, created_at, protected, verified. return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. features (List[str] | None, optional): Defined features of Twitter User Object on which similarity will be computed. Must be from: followers_count, friends_count, listed_count, favourites_count, statuses_count. Defaults to None. Raises: ValueError: If invalid comparison attribute was provided. Returns: dict | list: Results of requested comparison attribute(s). Referencs: https://mathun3003.github.io/PySNA/user-guide/overview/TwitterAPI/#compare_users \"\"\" # users list must contain at least two elements assert len(users) > 1, \"'users' list must contain at least two elements, {} was/were provided\".format(len(users)) # catch if feature vector contains only numeric values, and contains at least two elements if features: assert len(features) > 1, \"'features' list must have at least two elements. {} was/were given\".format(len(features)) for feat in features: if feat not in get_args(self.SIMILARITY_FEATURES_COMPARE_USERS): raise ValueError(f\"Only numeric features are supported. Must be from: {', '.join(get_args(self.SIMILARITY_FEATURES_COMPARE_USERS))}. You passed in {feat}\") # if single comparison attribute was provided as string if isinstance(compare, str): # change to list object compare = [compare] # init empty dict to store results results = dict() # iterate over comparison attributes for attr in compare: # if invalid attribute was provided if attr not in get_args(self.LITERALS_COMPARE_USERS): raise ValueError(\"Invalid attribute for '{}'\".format(attr)) # match comparison attributes match attr: # compare relationships between two users case \"relationship\": results[attr] = self.fetcher.get_relationship_pairs(users) # compare number of followers case \"followers_count\": # get individual followers followers = {user: self.fetcher.get_user_object(user).followers_count for user in users} # add descriptive metrics followers_with_metrics = self.data_processor.calc_descriptive_metrics(followers) results[attr] = followers_with_metrics # compare number of friends case \"followees_count\": # get individual followees followees = {user: self.fetcher.get_user_object(user).friends_count for user in users} # add descriptive metrics followees = self.data_processor.calc_descriptive_metrics(followees) results[attr] = followees # compare number of Tweets issued by each user case \"tweets_count\": # get individual statuses counts tweets = {user: self.fetcher.get_user_object(user).statuses_count for user in users} # add descriptive metrics tweets = self.data_processor.calc_descriptive_metrics(tweets) results[attr] = tweets # compare number of likes issued by each user case \"favourites_count\": # get individual likes likes = {user: self.fetcher.get_user_object(user).favourites_count for user in users} # add descriptive metrics likes = self.data_processor.calc_descriptive_metrics(likes) results[attr] = likes # compare protected attribute of users case \"protected\": results[attr] = {user: self.fetcher.get_user_object(user).protected for user in users} # compare verified attribute for users case \"verified\": results[attr] = {user: self.fetcher.get_user_object(user).verified for user in users} # get common followers case \"common_followers\": # get individual followers first individual_followers = [self.fetcher.get_user_follower_ids(user) for user in users] # get common followers by calculating the intersection common_followers = self.data_processor.intersection(individual_followers) results[attr] = common_followers # get distinct followers case \"distinct_followers\": # get individual followers first individual_followers = {user: self.fetcher.get_user_follower_ids(user) for user in users} # get distinct followers by calculating the difference of each set distinct_followers = self.data_processor.difference(individual_followers) results[attr] = distinct_followers # get common followees case \"common_followees\": # get individual followees first individual_followees = [self.fetcher.get_user_followee_ids(user) for user in users] # get common followees by calculating the intersection common_followees = self.data_processor.intersection(individual_followees) results[attr] = common_followees # get distinct followees case \"distinct_followees\": # get individual followees first individual_followees = {user: self.fetcher.get_user_followee_ids(user) for user in users} # get distinct followees by calculating the difference of each set distinct_followees = self.data_processor.difference(individual_followees) results[attr] = distinct_followees # get common liked tweets case \"commonly_liked_tweets\": # get individual liked tweets first individual_likes = [self.fetcher.get_liked_tweets_ids(user) for user in users] # get common liked tweets by calculating the intersection common_likes = self.data_processor.intersection(individual_likes) results[attr] = common_likes # get distinct liked tweets case \"distinctly_liked_tweets\": # get individual liked tweets first individual_likes = {user: self.fetcher.get_liked_tweets_ids(user) for user in users} # get distinct liked tweets by calculating the difference for each set distinct_likes = self.data_processor.difference(individual_likes) results[attr] = distinct_likes # compute similarity between two users basd on the defined features case \"similarity\": # feature list object must be defined if features is None: raise ValueError(\"'features' list must be provided.\") # get serialized user objects first user_objs = [self.fetcher.get_user_object(user)._json for user in users] # calculate similarity based on defined feature vector results[attr] = self.data_processor.calc_similarity(user_objs=user_objs, features=features) # compare creaation dates case \"created_at\": # get individual creation dates first creation_dates = {user: self.fetcher.get_user_object(user).created_at for user in users} # add datetime metrics creation_dates = self.data_processor.calc_datetime_metrics(creation_dates) results[attr] = creation_dates # if comparison attribute was not found case _: results[attr] = None # if timestamp should be returned if return_timestamp: results[\"utc_timestamp\"] = strf_datetime(datetime.utcnow(), format=\"%Y-%m-%d %H:%M:%S.%f\") return self._handle_output(results) tweet_info This function allows to request tweet information from a tweet object. Function: TwitterAPI.tweet_info(tweet_id: str | int, attributes: List[LITERALS_TWEET_INFO] | str, return_timestamp: bool = False) Args: tweet_id (str | int): Tweet ID attributes (List[LITERALS_TWEET_INFO] | str): Attributes of the Tweet object. These must be from this list . return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. This function takes in a tweet ID as string or integer representation. The attributes are passed in by a list object or by a single string. For a single provided attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. If the requested attribute for the objet is not available, None will be returned. Source Code def tweet_info(self, tweet_id: str | int, attributes: List[LITERALS_TWEET_INFO] | str, return_timestamp: bool = False) -> Any: \"\"\"Receive requested Tweet information from Tweet Object. For one attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Args: tweet_id (str | int): Tweet ID attributes (List[LITERALS_TWEET_INFO] | str): Attributes of the Tweet object. These must be from: id, id_str, full_text, display_text_range, truncated, created_at, entities, tweet_annotations, source, retweeters, in_reply_to_status_id, in_reply_to_status_id_str, in_reply_to_user_id, in_reply_to_user_id_str, in_reply_to_screen_name, user, contributors, coordinates, place, is_quote_status, public_metrics, quoting_users, liking_users, favorited, retweeted, retweeted_status, possibly_sensitive, lang, sentiment. return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. Raises: ValueError: If invalid attribute was provided. Returns: dict: Requested Tweet information. References: https://mathun3003.github.io/PySNA/user-guide/overview/TwitterAPI/#tweet_info \"\"\" # get tweet object tweet_obj = self.fetcher.get_tweet_object(tweet_id) # initialize empty dict to store request information tweet_info = dict() # if single string was provided if isinstance(attributes, str): # convert to list for iteration attributes = [attributes] for attr in attributes: # if invalid attribute was provided if attr not in get_args(self.LITERALS_TWEET_INFO): raise ValueError(\"Invalid attribute for '{}'\".format(attr)) # get default attributes from tweepy Status model elif attr in tweet_obj._json.keys(): tweet_info[attr] = tweet_obj._json[attr] # get all quoting users elif attr == \"quoting_users\": quoting_users = self.fetcher.get_quoting_users_ids(tweet_id) tweet_info[attr] = quoting_users # get all liking users elif attr == \"liking_users\": liking_users = self.fetcher.get_liking_users_ids(tweet_id) tweet_info[attr] = liking_users # get all retweeters elif attr == \"retweeters\": retweeters = self.fetcher.get_retweeters_ids(tweet_id) tweet_info[attr] = retweeters # get public metrics elif attr == \"public_metrics\": tweet_info[attr] = self.fetcher.get_public_metrics(tweet_id) # get context annotations elif attr == \"tweet_annotations\": tweet_info[attr] = self.fetcher.get_context_annotations_and_entities(tweet_id) # get tweet sentiment elif attr == \"sentiment\": tweet_info[attr] = self.data_processor.detect_tweet_sentiment(tweet_obj.full_text) # if attribute was not found else: tweet_info[attr] = None # if timestamp should be returned if return_timestamp: tweet_info[\"utc_timestamp\"] = strf_datetime(datetime.utcnow(), format=\"%Y-%m-%d %H:%M:%S.%f\") return self._handle_output(tweet_info) compare_tweets This function allows a comparison of multiple tweets. Function: TwitterAPI.compare_tweets(tweet_ids: List[str | int], compare: str | List[LITERALS_COMPARE_TWEETS], return_timestamp: bool = False, features: List[str] | None = None) Args: tweets (List[str | int]): List of Tweet IDs. compare (str | List[LITERALS_COMPARE_TWEETS]): Comparison attribute. Needs to be from the this list . return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. features (List[str] | None, optional): Defined features of Twitter User Object on which similarity will be computed. Must be from the features list . Defaults to None. This function takes in multiple tweet IDs as string or integer representation. The comparison attributes are passed in by a list object or by a single string. For a single attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Source Code def compare_tweets(self, tweet_ids: List[str | int], compare: str | List[LITERALS_COMPARE_TWEETS], return_timestamp: bool = False, features: List[str] | None = None) -> Any: \"\"\"Compare two or more Tweets with the specified comparison attribute. For one attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Args: tweets (List[str | int]): List of Tweet IDs. compare (str | List[LITERALS_COMPARE_TWEETS]): Comparison attribute. Needs to be from the following: view_count, like_count, retweet_count, quote_count, reply_count, common_quoting_users, distinct_quoting_users, common_liking_users, distinct_liking_users, common_retweeters, distinct_retweeters, similarity, created_at. return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. features (List[str] | None, optional): Defined features of Twitter User Object on which similarity will be computed. Must be from: retweet_count, reply_count, like_count, quote_count, impression_count. Defaults to None. Raises: AssertionError: If a list of one Tweet ID was provided. ValueError: If invalid comparison attribute was provided. Returns: dict: Requested results for comparison attribute. References: https://mathun3003.github.io/PySNA/user-guide/overview/TwitterAPI/#compare_tweets \"\"\" # tweets list must contain at least two IDs assert len(tweet_ids) > 1, \"'tweets' list object needs at least two entries, not {}\".format(len(tweet_ids)) # catch if feature vector contains only numeric values, and contains at least two elements if features: assert len(features) > 1, \"'features' list must have at least two elements. {} was/were given\".format(len(features)) for feat in features: if feat not in get_args(self.SIMILARITY_FEATURES_COMPARE_TWEETS): raise ValueError(f\"Only numeric features are supported. Must be from: {', '.join(get_args(self.SIMILARITY_FEATURES_COMPARE_TWEETS))}. You passed in {feat}.\") # if single comparison attribute was provided as string if isinstance(compare, str): # change to list object compare = [compare] # init empty dict to store results results = dict() # iterate over every given comparison atttribute for attr in compare: # if invalid attribute was provided if attr not in get_args(self.LITERALS_COMPARE_TWEETS): raise ValueError(\"Invalid attribute for '{}'\".format(attr)) # match comparison attribute match attr: # compare numer of views / impressions case \"view_count\": # get individual view_counts view_counts = {tweet_id: self.fetcher.get_public_metrics(tweet_id)[\"impression_count\"] for tweet_id in tweet_ids} # add descriptive metrics view_counts = self.data_processor.calc_descriptive_metrics(view_counts) results[attr] = view_counts # compare number of likes case \"like_count\": # get individual like_counts like_counts = {tweet_id: self.fetcher.get_public_metrics(tweet_id)[\"like_count\"] for tweet_id in tweet_ids} # add descriptive metrics like_counts = self.data_processor.calc_descriptive_metrics(like_counts) results[attr] = like_counts # compare number or retweets case \"retweet_count\": # get individual number of retweets retweet_counts = {tweet_id: self.fetcher.get_public_metrics(tweet_id)[\"retweet_count\"] for tweet_id in tweet_ids} # add descriptive metrics retweet_counts = self.data_processor.calc_descriptive_metrics(retweet_counts) results[attr] = retweet_counts # compare number of quotes case \"quote_count\": # get individual number of quotes quote_counts = {tweet_id: self.fetcher.get_public_metrics(tweet_id)[\"quote_count\"] for tweet_id in tweet_ids} # add descriptive metrics quote_counts = self.data_processor.calc_descriptive_metrics(quote_counts) results[attr] = quote_counts # compare number of commonts case \"reply_count\": # get individual number of replies first reply_counts = {tweet_id: self.fetcher.get_public_metrics(tweet_id)[\"reply_count\"] for tweet_id in tweet_ids} # add descriptive metrics reply_counts = self.data_processor.calc_descriptive_metrics(reply_counts) results[attr] = reply_counts # get all quoting users all Tweets have in common case \"common_quoting_users\": # get individual quoting users first quoting_users = [self.fetcher.get_quoting_users_ids(tweet_id) for tweet_id in tweet_ids] # get common quoting users by calculating the intersection common_quoting_users = self.data_processor.intersection(quoting_users) # return quoting users results[attr] = common_quoting_users # get distinct quoting users for each tweet case \"distinct_quoting_users\": # get individual quoting users first quoting_users = {tweet_id: self.fetcher.get_quoting_users_ids(tweet_id) for tweet_id in tweet_ids} # get distinct quoting users for each tweet by calculating the difference for each set distinct_quoting_users = self.data_processor.difference(quoting_users) results[attr] = distinct_quoting_users # get all liking users that all tweets have in common case \"common_liking_users\": # get individual liking users first liking_users = [self.fetcher.get_liking_users_ids(tweet_id) for tweet_id in tweet_ids] # get common liking users by calculating the intersection common_liking_users = self.data_processor.intersection(liking_users) # return common liking users results[attr] = common_liking_users # get distinct liking users of all tweets case \"distinct_liking_users\": # get individual liking users first liking_users = {tweet_id: self.fetcher.get_liking_users_ids(tweet_id) for tweet_id in tweet_ids} # get distinct liking users for each tweet by calculating the difference for each set distinct_liking_users = self.data_processor.difference(liking_users) results[attr] = distinct_liking_users # get all retweeters all tweets have in common case \"common_retweeters\": # get individual retweeters first retweeters = [self.fetcher.get_retweeters_ids(tweet_id) for tweet_id in tweet_ids] # get common retweeters by calculating the intersection common_retweeters = self.data_processor.intersection(retweeters) # return common retweeters results[attr] = common_retweeters # get distinct retweeters of all tweets case \"distinct_retweeters\": # get individual retweeters first retweeters = {tweet_id: self.fetcher.get_retweeters_ids(tweet_id) for tweet_id in tweet_ids} # get distinct retweeters by calculating the difference for each set distinct_retweeters = self.data_processor.difference(retweeters) results[attr] = distinct_retweeters # compute similarity between two tweets basd on the defined features case \"similarity\": # feature list object must be defined if features is None: raise ValueError(\"'features' list must be provided.\") # get public metrics for Tweet objects first public_metrics = {tweet_id: self.fetcher.get_public_metrics(tweet_id) for tweet_id in tweet_ids} # calculate similarity based on defined feature vector results[attr] = self.data_processor.calc_similarity(tweet_metrics=public_metrics, features=features) # compare creation dates of tweets case \"created_at\": # get individual creation dates first creation_dates = {tweet_id: self.fetcher.get_tweet_object(tweet_id).created_at for tweet_id in tweet_ids} # add datetime metrics creation_dates = self.data_processor.calc_datetime_metrics(creation_dates) results[attr] = creation_dates # if attribute was not found case _: results[attr] = None # if UTC timestamp should be returned if return_timestamp: results[\"utc_timestamp\"] = strf_datetime(datetime.utcnow(), format=\"%Y-%m-%d %H:%M:%S.%f\") return self._handle_output(results)","title":"TwitterAPI"},{"location":"maintenance/TwitterAPI/#twitterapi","text":"The TwitterAPI class forms the main class for user interaction and serves as a simple interface through encapsulation since the user can use all the functionalities of the package via the four main functions. All functionalities (except the utility function from the utils module) can be used via this class. The TwitterAPI class combines compatible data processing mechanisms with the respective data queries. This is achieved through composition whereby instances of the TwitterDataFetcher and TwitterDataProcessor are created within the class\u2019s constructor. Data processing mechanisms are outsourced to the functions of the TwitterDataProcessor instance whereas the data querying mechanisms are outsourced to the TwitterDataFetcher instance. This design decision ensures hiding implementation details from users or developers during usage or implementation and makes the code more structured. Thus, whenever any developer wants to make adjustments/fixes to the code, he or she has not to be aware of the code from the TwitterDataProcessor and TwitterDataFetcher instances. Contributing developers are able to understand this class's implementation by understanding the seperation of classes' concerns. This class serves the purpose of handling the input and output of user interactions through an interface. No further data processing or fetching is performed by this class. This class is built on top of the tweepy.Client class. The TwitterAPI class inherits the tweepy.Client class. Thus, every function from the inherited class will also be available in the TwitterAPI class, resulting in an package that extends the official Twitter API. The default behavior of the tweepy.Client class is overwritten but retained in order to extend this class. See the package architecture on the overview section of this chapter .","title":"TwitterAPI"},{"location":"maintenance/TwitterAPI/#initialization","text":"Import the TwitterAPI class from the api module or use the shortcut. from pysna.api import TwitterAPI # full path from pysna import TwitterAPI # shortcut api = TwitterAPI( bearer_token: Any | None = None, consumer_key: Any | None = None, consumer_secret: Any | None = None, access_token: Any | None = None, access_token_secret: Any | None = None, x_rapidapi_key: Any | None = None, x_rapidapi_host: Any | None = None, wait_on_rate_limit: bool = True ) and invoke a function: user_id = 123450897612 api.user_info(user_id, [\"screen_name\", \"followers_count\"]) Find the necessary secrets on the user guide instructions .","title":"Initialization"},{"location":"maintenance/TwitterAPI/#methods","text":"All functions have pre-defined input parameters (either for the attributes or compare arguments). They are stored inside the literal objects: TwitterAPI.LITERALS_USER_INFO : available attributes for a Twitter account. For more information, see here . TwitterAPI.LITERALS_COMPARE_USERS : available comparison attributes for Twitter accounts. For more information, see here . TwitterAPI.LITERALS_TWEET_INFO : available attributes for a tweet. For more information, see here . TwitterAPI.LITERALS_COMPARE_TWEETS : available comparison attributes for tweets. For more information, see here . Each (comparison) attribute is covered in the corresponding main function by iterations of a for loop. Whenever one of the four main functions is called, the required data resources are fetched by making API calls via the TwitterDataFetcher class for each specified (comparison) attribute and are processed by the TwitterDataProcessor class if necessary. For instance, when comparing multiple users on their common followers, individual followers for each user are fetched first and then processed by calculating the intersection set of all individual followers. If any new functionality is added to this class (e.g., get the length of a tweet by a length attribute), the new attribute has to be added to the corresponding literal object. In addition, the comparison functions also have a features argument which is used to define a feature vector for comparison. The available similarity features for users and tweets are also specified in separate literal objects: TwitterAPI.SIMILARITY_FEATURES_COMPARE_USERS : available similarity features for the TwitterAPI.compare_users function. For more information, see here . TwitterAPI.SIMILARITY_FEATURES_COMPARE_TWEETS : available similarity features for the TwitterAPI.compare_tweets function. For more information, see here .","title":"Methods"},{"location":"maintenance/TwitterAPI/#handle_output-private","text":"This function is designed to handle the output of the four main functions accordingly. To avoid accessing a returned dictionary with only one available key, this function returns either the single value from the one-key dictionary or the full dictionary itself if multiple keys are available. Function: TwitterAPI._handle_output(output: dict) This function is private and, thus, not intended for external use. This function was designed to facilitate the use of the package without the need for accessing a returned one-key dictionary.","title":"handle_output (private)"},{"location":"maintenance/TwitterAPI/#user_info","text":"This function allows to request user information from a Twitter account. Function: TwitterAPI.user_info(user: str | int, attributes: List[LITERALS_USER_INFO] | str, return_timestamp: bool = False) Args: user (str | int): Twitter User either specified by corresponding ID or screen name. attributes (List[str] | str): Attributes of the User object. These must be from this list . return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. This function takes in a Twitter user identifier (i.e., an ID or unique screen name). The attributes are passed in by a list object or by a single string. For a single provided attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. If the requested attribute for the objet is not available, None will be returned. Source Code def user_info(self, user: str | int, attributes: List[LITERALS_USER_INFO] | str, return_timestamp: bool = False) -> Any: \"\"\"Receive requested user information from Twitter User Object. For one attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Args: user (str | int): Twitter User either specified by corresponding ID or screen name. attributes (List[str] | str): Attributes of the User object. These must be from: id, id_str, name, screen_name, followers, followees, location, description, url, entities, protected, followers_count, friends_count, listed_count, created_at, latest_activity, last_active, liked_tweets, composed_tweets, favourites_count, verified, statuses_count, status, contributors_enabled, profile_image_url_https, profile_banner_url, default_profile, default_profile_image, withheld_in_countries, bot_scores return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. Raises: KeyError: If invalid attribute was provided. ValueError: If Botometer secrets were not provided. Returns: dict: Requested user information. References: https://mathun3003.github.io/PySNA/user-guide/overview/TwitterAPI/#user_info \"\"\" # catch Botometer API secrets before iteration over attributes. if \"bot_scores\" in attributes: if (self._x_rapidapi_key is None) or (self._x_rapidapi_host is None): raise ValueError(\"'X_RAPIDAPI_KEY' and 'X_RAPIDAPI_HOST' secrets for Botometer API need to be provided.\") # initialize empty dict to store requested attributes user_info = dict() # if single string was provided if isinstance(attributes, str): # convert to list for iteration attributes = [attributes] # get user object user_obj = self.fetcher.get_user_object(user) # loop through the list of attributes and add them to the dictionary for attr in attributes: # if invalid attribute was provided if attr not in get_args(self.LITERALS_USER_INFO): raise ValueError(\"Invalid attribute for '{}'\".format(attr)) # if the desired attribute is in default user object returned by the v1 Search API elif attr in user_obj._json.keys(): user_info[attr] = user_obj._json[attr] # get information about user's followers elif attr == \"followers\": user_info[attr] = self.data_processor.extract_followers(user_obj) # get information about user's followees elif attr == \"followees\": user_info[attr] = self.data_processor.extract_followees(user_obj) # get all liked tweets of user elif attr == \"liked_tweets\": # get page results first liked_tweets = self.fetcher.get_liked_tweets_ids(user) user_info[attr] = liked_tweets # get all composed tweets elif attr == \"composed_tweets\": # get page results first composed_tweets = self.fetcher.get_composed_tweets_ids(user) user_info[attr] = composed_tweets # get user's latest activity elif attr == \"latest_activity\": user_info[attr] = self.fetcher.get_latest_activity(user) # get user's latest activity date elif attr == \"last_active\": user_info[attr] = self.fetcher.get_latest_activity_date(user) # get user's botometer scores elif attr == \"bot_scores\": user_info[attr] = self.fetcher.get_botometer_scores(user) # if attribute was not found else: user_info[attr] = None # if timestamp should be returned if return_timestamp: user_info[\"utc_timestamp\"] = strf_datetime(datetime.utcnow(), format=\"%Y-%m-%d %H:%M:%S.%f\") return self._handle_output(user_info)","title":"user_info"},{"location":"maintenance/TwitterAPI/#compare_users","text":"This function allows a comparison of multiple Twitter accounts. Function: TwitterAPI.compare_users(users: List[str | int], compare: str | List[LITERALS_COMPARE_USERS], return_timestamp: bool = False, features: List[str] | None = None) Args: users (List[str | int]): User IDs or screen names compare (str): Comparison attribute. Must be from this list . return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. features (List[str] | None, optional): Defined features of Twitter User Object on which similarity will be computed. Must be from the features list . Defaults to None. This function takes in multiple Twitter user identifiers (i.e., IDs or unique screen names). The comparison attributes are passed in by a list object or by a single string. For a single attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Source Code def compare_users(self, users: List[str | int], compare: str | List[LITERALS_COMPARE_USERS], return_timestamp: bool = False, features: List[str] | None = None) -> Any: \"\"\"Compare two or more users with the specified comparison attribute(s). For one attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Args: users (List[str | int]): User IDs or screen names compare (str): Comparison attribute. Must be from: relationship, followers_count, followees_count, tweets_count, favourites_count, common_followers, distinct_followers, common_followees, distinct_followees, commonly_liked_tweets, distinctly_liked_tweets, similarity, created_at, protected, verified. return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. features (List[str] | None, optional): Defined features of Twitter User Object on which similarity will be computed. Must be from: followers_count, friends_count, listed_count, favourites_count, statuses_count. Defaults to None. Raises: ValueError: If invalid comparison attribute was provided. Returns: dict | list: Results of requested comparison attribute(s). Referencs: https://mathun3003.github.io/PySNA/user-guide/overview/TwitterAPI/#compare_users \"\"\" # users list must contain at least two elements assert len(users) > 1, \"'users' list must contain at least two elements, {} was/were provided\".format(len(users)) # catch if feature vector contains only numeric values, and contains at least two elements if features: assert len(features) > 1, \"'features' list must have at least two elements. {} was/were given\".format(len(features)) for feat in features: if feat not in get_args(self.SIMILARITY_FEATURES_COMPARE_USERS): raise ValueError(f\"Only numeric features are supported. Must be from: {', '.join(get_args(self.SIMILARITY_FEATURES_COMPARE_USERS))}. You passed in {feat}\") # if single comparison attribute was provided as string if isinstance(compare, str): # change to list object compare = [compare] # init empty dict to store results results = dict() # iterate over comparison attributes for attr in compare: # if invalid attribute was provided if attr not in get_args(self.LITERALS_COMPARE_USERS): raise ValueError(\"Invalid attribute for '{}'\".format(attr)) # match comparison attributes match attr: # compare relationships between two users case \"relationship\": results[attr] = self.fetcher.get_relationship_pairs(users) # compare number of followers case \"followers_count\": # get individual followers followers = {user: self.fetcher.get_user_object(user).followers_count for user in users} # add descriptive metrics followers_with_metrics = self.data_processor.calc_descriptive_metrics(followers) results[attr] = followers_with_metrics # compare number of friends case \"followees_count\": # get individual followees followees = {user: self.fetcher.get_user_object(user).friends_count for user in users} # add descriptive metrics followees = self.data_processor.calc_descriptive_metrics(followees) results[attr] = followees # compare number of Tweets issued by each user case \"tweets_count\": # get individual statuses counts tweets = {user: self.fetcher.get_user_object(user).statuses_count for user in users} # add descriptive metrics tweets = self.data_processor.calc_descriptive_metrics(tweets) results[attr] = tweets # compare number of likes issued by each user case \"favourites_count\": # get individual likes likes = {user: self.fetcher.get_user_object(user).favourites_count for user in users} # add descriptive metrics likes = self.data_processor.calc_descriptive_metrics(likes) results[attr] = likes # compare protected attribute of users case \"protected\": results[attr] = {user: self.fetcher.get_user_object(user).protected for user in users} # compare verified attribute for users case \"verified\": results[attr] = {user: self.fetcher.get_user_object(user).verified for user in users} # get common followers case \"common_followers\": # get individual followers first individual_followers = [self.fetcher.get_user_follower_ids(user) for user in users] # get common followers by calculating the intersection common_followers = self.data_processor.intersection(individual_followers) results[attr] = common_followers # get distinct followers case \"distinct_followers\": # get individual followers first individual_followers = {user: self.fetcher.get_user_follower_ids(user) for user in users} # get distinct followers by calculating the difference of each set distinct_followers = self.data_processor.difference(individual_followers) results[attr] = distinct_followers # get common followees case \"common_followees\": # get individual followees first individual_followees = [self.fetcher.get_user_followee_ids(user) for user in users] # get common followees by calculating the intersection common_followees = self.data_processor.intersection(individual_followees) results[attr] = common_followees # get distinct followees case \"distinct_followees\": # get individual followees first individual_followees = {user: self.fetcher.get_user_followee_ids(user) for user in users} # get distinct followees by calculating the difference of each set distinct_followees = self.data_processor.difference(individual_followees) results[attr] = distinct_followees # get common liked tweets case \"commonly_liked_tweets\": # get individual liked tweets first individual_likes = [self.fetcher.get_liked_tweets_ids(user) for user in users] # get common liked tweets by calculating the intersection common_likes = self.data_processor.intersection(individual_likes) results[attr] = common_likes # get distinct liked tweets case \"distinctly_liked_tweets\": # get individual liked tweets first individual_likes = {user: self.fetcher.get_liked_tweets_ids(user) for user in users} # get distinct liked tweets by calculating the difference for each set distinct_likes = self.data_processor.difference(individual_likes) results[attr] = distinct_likes # compute similarity between two users basd on the defined features case \"similarity\": # feature list object must be defined if features is None: raise ValueError(\"'features' list must be provided.\") # get serialized user objects first user_objs = [self.fetcher.get_user_object(user)._json for user in users] # calculate similarity based on defined feature vector results[attr] = self.data_processor.calc_similarity(user_objs=user_objs, features=features) # compare creaation dates case \"created_at\": # get individual creation dates first creation_dates = {user: self.fetcher.get_user_object(user).created_at for user in users} # add datetime metrics creation_dates = self.data_processor.calc_datetime_metrics(creation_dates) results[attr] = creation_dates # if comparison attribute was not found case _: results[attr] = None # if timestamp should be returned if return_timestamp: results[\"utc_timestamp\"] = strf_datetime(datetime.utcnow(), format=\"%Y-%m-%d %H:%M:%S.%f\") return self._handle_output(results)","title":"compare_users"},{"location":"maintenance/TwitterAPI/#tweet_info","text":"This function allows to request tweet information from a tweet object. Function: TwitterAPI.tweet_info(tweet_id: str | int, attributes: List[LITERALS_TWEET_INFO] | str, return_timestamp: bool = False) Args: tweet_id (str | int): Tweet ID attributes (List[LITERALS_TWEET_INFO] | str): Attributes of the Tweet object. These must be from this list . return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. This function takes in a tweet ID as string or integer representation. The attributes are passed in by a list object or by a single string. For a single provided attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. If the requested attribute for the objet is not available, None will be returned. Source Code def tweet_info(self, tweet_id: str | int, attributes: List[LITERALS_TWEET_INFO] | str, return_timestamp: bool = False) -> Any: \"\"\"Receive requested Tweet information from Tweet Object. For one attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Args: tweet_id (str | int): Tweet ID attributes (List[LITERALS_TWEET_INFO] | str): Attributes of the Tweet object. These must be from: id, id_str, full_text, display_text_range, truncated, created_at, entities, tweet_annotations, source, retweeters, in_reply_to_status_id, in_reply_to_status_id_str, in_reply_to_user_id, in_reply_to_user_id_str, in_reply_to_screen_name, user, contributors, coordinates, place, is_quote_status, public_metrics, quoting_users, liking_users, favorited, retweeted, retweeted_status, possibly_sensitive, lang, sentiment. return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. Raises: ValueError: If invalid attribute was provided. Returns: dict: Requested Tweet information. References: https://mathun3003.github.io/PySNA/user-guide/overview/TwitterAPI/#tweet_info \"\"\" # get tweet object tweet_obj = self.fetcher.get_tweet_object(tweet_id) # initialize empty dict to store request information tweet_info = dict() # if single string was provided if isinstance(attributes, str): # convert to list for iteration attributes = [attributes] for attr in attributes: # if invalid attribute was provided if attr not in get_args(self.LITERALS_TWEET_INFO): raise ValueError(\"Invalid attribute for '{}'\".format(attr)) # get default attributes from tweepy Status model elif attr in tweet_obj._json.keys(): tweet_info[attr] = tweet_obj._json[attr] # get all quoting users elif attr == \"quoting_users\": quoting_users = self.fetcher.get_quoting_users_ids(tweet_id) tweet_info[attr] = quoting_users # get all liking users elif attr == \"liking_users\": liking_users = self.fetcher.get_liking_users_ids(tweet_id) tweet_info[attr] = liking_users # get all retweeters elif attr == \"retweeters\": retweeters = self.fetcher.get_retweeters_ids(tweet_id) tweet_info[attr] = retweeters # get public metrics elif attr == \"public_metrics\": tweet_info[attr] = self.fetcher.get_public_metrics(tweet_id) # get context annotations elif attr == \"tweet_annotations\": tweet_info[attr] = self.fetcher.get_context_annotations_and_entities(tweet_id) # get tweet sentiment elif attr == \"sentiment\": tweet_info[attr] = self.data_processor.detect_tweet_sentiment(tweet_obj.full_text) # if attribute was not found else: tweet_info[attr] = None # if timestamp should be returned if return_timestamp: tweet_info[\"utc_timestamp\"] = strf_datetime(datetime.utcnow(), format=\"%Y-%m-%d %H:%M:%S.%f\") return self._handle_output(tweet_info)","title":"tweet_info"},{"location":"maintenance/TwitterAPI/#compare_tweets","text":"This function allows a comparison of multiple tweets. Function: TwitterAPI.compare_tweets(tweet_ids: List[str | int], compare: str | List[LITERALS_COMPARE_TWEETS], return_timestamp: bool = False, features: List[str] | None = None) Args: tweets (List[str | int]): List of Tweet IDs. compare (str | List[LITERALS_COMPARE_TWEETS]): Comparison attribute. Needs to be from the this list . return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. features (List[str] | None, optional): Defined features of Twitter User Object on which similarity will be computed. Must be from the features list . Defaults to None. This function takes in multiple tweet IDs as string or integer representation. The comparison attributes are passed in by a list object or by a single string. For a single attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Source Code def compare_tweets(self, tweet_ids: List[str | int], compare: str | List[LITERALS_COMPARE_TWEETS], return_timestamp: bool = False, features: List[str] | None = None) -> Any: \"\"\"Compare two or more Tweets with the specified comparison attribute. For one attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Args: tweets (List[str | int]): List of Tweet IDs. compare (str | List[LITERALS_COMPARE_TWEETS]): Comparison attribute. Needs to be from the following: view_count, like_count, retweet_count, quote_count, reply_count, common_quoting_users, distinct_quoting_users, common_liking_users, distinct_liking_users, common_retweeters, distinct_retweeters, similarity, created_at. return_timestamp (bool, optional): Add UTC Timestamp to results. Defaults to False. features (List[str] | None, optional): Defined features of Twitter User Object on which similarity will be computed. Must be from: retweet_count, reply_count, like_count, quote_count, impression_count. Defaults to None. Raises: AssertionError: If a list of one Tweet ID was provided. ValueError: If invalid comparison attribute was provided. Returns: dict: Requested results for comparison attribute. References: https://mathun3003.github.io/PySNA/user-guide/overview/TwitterAPI/#compare_tweets \"\"\" # tweets list must contain at least two IDs assert len(tweet_ids) > 1, \"'tweets' list object needs at least two entries, not {}\".format(len(tweet_ids)) # catch if feature vector contains only numeric values, and contains at least two elements if features: assert len(features) > 1, \"'features' list must have at least two elements. {} was/were given\".format(len(features)) for feat in features: if feat not in get_args(self.SIMILARITY_FEATURES_COMPARE_TWEETS): raise ValueError(f\"Only numeric features are supported. Must be from: {', '.join(get_args(self.SIMILARITY_FEATURES_COMPARE_TWEETS))}. You passed in {feat}.\") # if single comparison attribute was provided as string if isinstance(compare, str): # change to list object compare = [compare] # init empty dict to store results results = dict() # iterate over every given comparison atttribute for attr in compare: # if invalid attribute was provided if attr not in get_args(self.LITERALS_COMPARE_TWEETS): raise ValueError(\"Invalid attribute for '{}'\".format(attr)) # match comparison attribute match attr: # compare numer of views / impressions case \"view_count\": # get individual view_counts view_counts = {tweet_id: self.fetcher.get_public_metrics(tweet_id)[\"impression_count\"] for tweet_id in tweet_ids} # add descriptive metrics view_counts = self.data_processor.calc_descriptive_metrics(view_counts) results[attr] = view_counts # compare number of likes case \"like_count\": # get individual like_counts like_counts = {tweet_id: self.fetcher.get_public_metrics(tweet_id)[\"like_count\"] for tweet_id in tweet_ids} # add descriptive metrics like_counts = self.data_processor.calc_descriptive_metrics(like_counts) results[attr] = like_counts # compare number or retweets case \"retweet_count\": # get individual number of retweets retweet_counts = {tweet_id: self.fetcher.get_public_metrics(tweet_id)[\"retweet_count\"] for tweet_id in tweet_ids} # add descriptive metrics retweet_counts = self.data_processor.calc_descriptive_metrics(retweet_counts) results[attr] = retweet_counts # compare number of quotes case \"quote_count\": # get individual number of quotes quote_counts = {tweet_id: self.fetcher.get_public_metrics(tweet_id)[\"quote_count\"] for tweet_id in tweet_ids} # add descriptive metrics quote_counts = self.data_processor.calc_descriptive_metrics(quote_counts) results[attr] = quote_counts # compare number of commonts case \"reply_count\": # get individual number of replies first reply_counts = {tweet_id: self.fetcher.get_public_metrics(tweet_id)[\"reply_count\"] for tweet_id in tweet_ids} # add descriptive metrics reply_counts = self.data_processor.calc_descriptive_metrics(reply_counts) results[attr] = reply_counts # get all quoting users all Tweets have in common case \"common_quoting_users\": # get individual quoting users first quoting_users = [self.fetcher.get_quoting_users_ids(tweet_id) for tweet_id in tweet_ids] # get common quoting users by calculating the intersection common_quoting_users = self.data_processor.intersection(quoting_users) # return quoting users results[attr] = common_quoting_users # get distinct quoting users for each tweet case \"distinct_quoting_users\": # get individual quoting users first quoting_users = {tweet_id: self.fetcher.get_quoting_users_ids(tweet_id) for tweet_id in tweet_ids} # get distinct quoting users for each tweet by calculating the difference for each set distinct_quoting_users = self.data_processor.difference(quoting_users) results[attr] = distinct_quoting_users # get all liking users that all tweets have in common case \"common_liking_users\": # get individual liking users first liking_users = [self.fetcher.get_liking_users_ids(tweet_id) for tweet_id in tweet_ids] # get common liking users by calculating the intersection common_liking_users = self.data_processor.intersection(liking_users) # return common liking users results[attr] = common_liking_users # get distinct liking users of all tweets case \"distinct_liking_users\": # get individual liking users first liking_users = {tweet_id: self.fetcher.get_liking_users_ids(tweet_id) for tweet_id in tweet_ids} # get distinct liking users for each tweet by calculating the difference for each set distinct_liking_users = self.data_processor.difference(liking_users) results[attr] = distinct_liking_users # get all retweeters all tweets have in common case \"common_retweeters\": # get individual retweeters first retweeters = [self.fetcher.get_retweeters_ids(tweet_id) for tweet_id in tweet_ids] # get common retweeters by calculating the intersection common_retweeters = self.data_processor.intersection(retweeters) # return common retweeters results[attr] = common_retweeters # get distinct retweeters of all tweets case \"distinct_retweeters\": # get individual retweeters first retweeters = {tweet_id: self.fetcher.get_retweeters_ids(tweet_id) for tweet_id in tweet_ids} # get distinct retweeters by calculating the difference for each set distinct_retweeters = self.data_processor.difference(retweeters) results[attr] = distinct_retweeters # compute similarity between two tweets basd on the defined features case \"similarity\": # feature list object must be defined if features is None: raise ValueError(\"'features' list must be provided.\") # get public metrics for Tweet objects first public_metrics = {tweet_id: self.fetcher.get_public_metrics(tweet_id) for tweet_id in tweet_ids} # calculate similarity based on defined feature vector results[attr] = self.data_processor.calc_similarity(tweet_metrics=public_metrics, features=features) # compare creation dates of tweets case \"created_at\": # get individual creation dates first creation_dates = {tweet_id: self.fetcher.get_tweet_object(tweet_id).created_at for tweet_id in tweet_ids} # add datetime metrics creation_dates = self.data_processor.calc_datetime_metrics(creation_dates) results[attr] = creation_dates # if attribute was not found case _: results[attr] = None # if UTC timestamp should be returned if return_timestamp: results[\"utc_timestamp\"] = strf_datetime(datetime.utcnow(), format=\"%Y-%m-%d %H:%M:%S.%f\") return self._handle_output(results)","title":"compare_tweets"},{"location":"maintenance/TwitterDataFetcher/","text":"TwitterDataFetcher The TwitterDataFetcher class is used to specifically query Twitter data. To simplify the queries to the Twitter API, this software component uses already existing open-source software for interacting with the API, namely the Tweepy Python package . It uses the Tweepy Client class to query the data dictionaries of the Twitter Search API v2 as well as the Tweepy API class to access the data dictionaries based on the Twitter Search API v1. The Twitter Search API v1 is mainly used to query user and tweet objects. Although this API version is partially deprecated, it offers a comparable content to the latest API version and often requires less API calls to receive the same information compared to the v2 API. Additional direct requests to the Twitter Search API v2 are performed, too, using the Python requests library to query endpoints that have been migrated or deprecated in the Tweepy package. This class can also be used to in isolation to collect Twitter data. It requires, therefore, authentication for the Twitter platform. Provide the secrets for the Twitter API and, if desired, for the Botometer API. You can find a list of required secrets in the user guide for the TwitterAPI class. This class has the concern to fetch Twitter data. No further processing is performed within this class. Initialization If you want to use this class for data processing or other package components, follow the steps below. Import the TwitterDataFetcher class from the fetch module. from pysna.fetch import TwitterDataFetcher fetcher = TwitterDataFetcher( bearer_token: Any | None = None, consumer_key: Any | None = None, consumer_secret: Any | None = None, access_token: Any | None = None, access_token_secret: Any | None = None, x_rapidapi_key: Any | None = None, x_rapidapi_host: Any | None = None ) and invoke a function: user_id = 123450897612 fetcher.get_latest_activity(user_id) Find the necessary secrets on the user guide instructions . Methods Private Methods manual_request Performs a manual request to the Twitter API. Returns JSON formatted API response. Function: TwitterDataFetcher._manual_request(url: str, method: str = \"GET\", header: dict | None = None, payload: dict | None = None, additional_fields: Dict[str, List[str]] | None = None) Args: url (str): API URL (without specified fields) method (str): Request method according to REST. Defaults to \"GET\". header : Custom HTTP Header. Defaults to None. payload : JSON data for HTTP requests. Defaults to None. additional_fields (Dict[str, List[str]] | None, optional): Fields can be specified (e.g., tweet.fields) according to the official API reference. Defaults to None. The function will raise an exception if the response status code is unlike 200. With this function, performig manual requests is facilitated as the query string is built by the function based on the provided input arguments. The url argument has to be provided in raw form (i.e., without any parameters or fields). The method argument allows to specify the REST request method (i.e., GET, POST, PUT, DELETE). Defaults to GET. The header argument allows to specify a custom header. This is useful if another API besides the Twitter API is fetched. If no custom header is provided, the default header for the Twitter API authentification is used based on the provided bearer_token during instantiation. The payload argument allows to send data for a POST or PUT request. The data must be provided as a dictionary. The additional_fields argument is used to specify Twitter fields (i.e., user fields or tweet fields) and, thus, enhance the query and return additional information. The argument can be used as follows: {\"tweet.fields\": [\"public_metrics\"]} The function will then build the query string and send it to the API. You can find the full list of Twitter fields in the documentation: https://developer.twitter.com/en/docs/twitter-api/fields Source Code def _manual_request(self, url: str, method: str = \"GET\", header: dict | None = None, payload: dict | None = None, additional_fields: Dict[str, List[str]] | None = None) -> dict: \"\"\"Perform a manual request to the Twitter API. Args: url (str): API URL (without specified fields) method (str): Request method according to REST. Defaults to \"GET\". header (dict | None): Custom HTTP Header. Defaults to None. payload (dict | None): JSON data for HTTP requests. Defaults to None. additional_fields (Dict[str, List[str]] | None, optional): Fields can be specified (e.g., tweet.fields) according to the official API reference. Defaults to None. Raises: Exception: If status code != 200. Returns: dict: JSON formatted response of API request. \"\"\" # if additional_fields were provided if additional_fields: # init empty string fields = \"?\" # create fields string dynamically for every field in additional_fields for field in additional_fields.keys(): # e.g., in format \"tweet.fields=lang,author_id\" fields += f\"{field}={','.join(additional_fields[field])}&\" # append fields to url url += fields[:-1] if header is None: # set header header = {\"Authorization\": f\"Bearer {self._bearer_token}\"} response = requests.request(method=method, url=url, headers=header, json=payload) if response.status_code != 200: raise Exception(\"Request returned an error: {} {}\".format(response.status_code, response.text)) return response.json() paginate Custom pagination function It turns out that the pagination functions from the Tweepy Python packge are considerably slower than doing the pagination manually. For this reason, this function was designed. Function: TwitterDataFetcher._paginate(func, params: Dict[str, str | int], limit: int | None = None, response_attribute: str = \"data\", page_attribute: str | None = None) Args: func : Function used for pagination params (Dict[str, str | int]): Dict containing request parameters. Must be of the form {'id': ..., 'limit': ..., 'pagination_token': ...} limit (int | None, optional): Maximum number of results. Defaults to None, thus, no limit. response_attribute (str, optional): Attribute of the Response object. Defaults to \"data\". Options: [\"data\", \"includes\"] page_attribute (str, optional): The attribute that should be extracted for every entry of a page. Defaults to None. The params argument is used to specify the parameters for the next page. Therefore, an id is needed as well as a key indicating the maximm number of results (i.e., limit ). None indicates that no limit is desired and, thus, all available results will be returned. The pagination_token key can be set to None initially. This pagination token will be reset during iteraion. In case, you wish to start from a different page than the first one, provide a pagination token. All parameters must be provided via a dictionary of the form: {\"id\": 1234456, \"limit\": None, # no limit \"pagination_token\": None} The response_attribute argument specifies where to collect the data from the response. If data is specified, the results are received from the default attribute field of the response. If includes is specified, the results are obtained from the additional information provided by the Twitter fields.` The page_attribute argument specifies what attribute should be extracted for every entry of a page. For instance, if this argument is set to id , then the IDs will be extracted from every entry (e.g., user IDs of user objects). Inside that function, a counter is incremented for every result that has been fetched. If the limit was reached, the function will break out the loop and will return immediately the obtained results. Otherwise, the function will check if last page was reached and will fetch the next page (if available). Source Code def _paginate(self, func, params: Dict[str, str | int], limit: int | None = None, response_attribute: str = \"data\", page_attribute: str | None = None) -> list: \"\"\"Pagination function Args: func: Function used for pagination params (Dict[str, str | int]): Dict containing request parameters. Should be of the form {'id': ..., 'max_results': ..., 'pagination_token': ...} limit (int | None, optional): Maximum number of results. Defaults to None, thus, no limit. response_attribute (str, optional): Attribute of the Response object. Defaults to \"data\". Options: [\"data\", \"includes\"] Raises: KeyError: 'id', 'max_results', and 'pagination_token' should be provided in the params dict. Returns: set: Results \"\"\" # init counter counter = 0 # init empty results set results = list() # set break out var break_out = False while not break_out: # make request response = func(**params) # if any data exists if response.__getattribute__(response_attribute) is not None: # iterate over response results for item in response.__getattribute__(response_attribute): # add result if page_attribute is None: results.append(item) else: results.append(item.__getattribute__(page_attribute)) # increment counter counter += 1 # if limit was reached, break if (limit is not None) and (counter == limit): # set break_out var to true break_out = True break # if last page was reached if \"next_token\" not in response.meta: break # else, set new pagination token for next iteration else: params[\"pagination_token\"] = response.meta[\"next_token\"] # if no data exists, break else: break return results Twitter user related methods get_user_object Request Twitter user object using Tweepy. The user object is fetched from the Twitter Search API v1. For this, the Tweepy API class is used. Function: TwitterDataFetcher.get_user_object(user: str | int) The function takes in either the user ID as string or integer or the user's unique screen name. It returns the requested API v1 user object. The function handles the performed request based on what user identifier was given. If the requested user has been suspended from Twitter, an error will be returned and a messeage will be logged to stdout. Source Code def get_user_object(self, user: str | int) -> tweepy.models.User: \"\"\"Request Twitter User Object via tweepy Args: user (str): Either User ID or screen name Returns: tweepy.User: Twitter User object from tweepy \"\"\" try: # check if string for user1 is convertible to int in order to check for user ID or screen name if (isinstance(user, int)) or (user.isdigit()): # get profile for user by user ID user_obj = self.api.get_user(user_id=user) else: # get profile for user by screen name user_obj = self.api.get_user(screen_name=user) except tweepy.errors.Forbidden as e: # log to stdout log.error(\"403 Forbidden: access refused or access is not allowed.\") # if user ID was provided if user.isdigit() or isinstance(user, int): url = f\"https://api.twitter.com/2/users/{user}\" else: # if screen name was provided url = f\"https://api.twitter.com/2/users/by/username/{user}\" response = self._manual_request(url) # if an error occured that says the user has been suspended if any(\"User has been suspended\" in error[\"detail\"] for error in response[\"errors\"]): log.error(\"User has been suspended from Twitter. Requested user: {}\".format(user)) raise e else: raise e return user_obj get_user_follower_ids Request Twitter follower IDs from user. Function: TwitterDataFetcher.get_user_follower_ids(user: str | int) This function takes in a Twitter user identifier (either ID or unique screen name). It returns all follower user IDs from the specified user as a set. Here, the ``tweepy.Cursor```is used for pagination. The function handles the performed request based on what user identifier was given. Source Code def get_user_follower_ids(self, user: str | int) -> Set[int]: \"\"\"Request Twitter follower IDs from user Args: user (str | int): Either User ID or screen name. Returns: Set[int]: Array containing follower IDs \"\"\" # check if string for user1 is convertible to int in order to check for user ID or screen name if (isinstance(user, int)) or (user.isdigit()): params = {\"user_id\": user} else: params = {\"screen_name\": user} follower_ids = list() for page in tweepy.Cursor(self.api.get_follower_ids, **params).pages(): follower_ids.extend(page) return set(follower_ids) get_user_followee_ids Request Twitter followee IDs from user. Function: TwitterDataFetcher.get_user_followee_ids(user: str | int) This function takes in a Twitter user identifier (i.e., either ID or unique screen name) and returns a set containing all IDs from the user's followees (AKA friends or follows). The function handles the performed request based on what user identifier was given. Source Code def get_user_followee_ids(self, user: str | int) -> Set[int]: \"\"\"Request Twitter followee IDs from user Args: user (str): Either User ID or screen name. Returns: Set[int]: Array containing follow IDs \"\"\" # check if string for user1 is convertible to int in order to check for user ID or screen name if (isinstance(user, int)) or (user.isdigit()): params = {\"user_id\": user} else: params = {\"screen_name\": user} followee_ids = list() for page in tweepy.Cursor(self.api.get_friend_ids, **params).pages(): followee_ids.extend(page) return set(followee_ids) get_latest_activity Returns latest user's activity by fetching the top element from its timeline. Function: TwitterDataFetcher.get_latest_activity(user: str | int) This function takes in a Twitter user identifier (i.e., either ID or unique screen name) and returns the latest activity from the user's timeline. Therefore, the _manual_request function is used to request the corresponding endpoint . Often, this will be a tweet composed by the user itself. Then, all available data of that tweet will be returned as a dictionary. The function handles the performed request based on what user identifier was given. Source Code def get_latest_activity(self, user: str | int) -> dict: \"\"\"Returns latest user's activity by fetching the top element from its timeline. Args: user (str | int): User ID or screen name. Returns: dict: Latest activity. \"\"\" # if screen name was provided if (isinstance(user, str)) and (user.isdigit() is False): url = f\"https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name={user}&include_rts=true&trim_user=true&tweet_mode=extended\" # else go with user ID else: url = f\"https://api.twitter.com/1.1/statuses/user_timeline.json?user_id={user}&include_rts=true&trim_user=true&tweet_mode=extended\" response_json = self._manual_request(url) # return the first item since timeline is sorted descending return response_json[0] get_latest_activity_date Get latest activity date from specified user by fetching the top element from its timeline and extract the creation date. Function: TwitterDataFetcher.get_latest_activity_date(user: str | int) This function takes in a Twitter user identifier (i.e., either ID or unique screen name) and returns the latest activity date from the user's timeline. Therefore, the _manual_request function is used to request the corresponding endpoint . The latest activity date is determined by fetching the latest activity from the user's timeline first, and then extracting the creation date. Usually, this will be a tweet composed by the user. If this is the case, the creation date of that tweet will be returned, representing the latest public available activity date. Source Code def get_latest_activity_date(self, user: str | int) -> str: \"\"\"Get latest activity date from specified user by fetching the top element from its timeline. Args: user (str | int): User ID or screen name. Returns: str: Activity date of latest activity. \"\"\" # if screen name was provided if (isinstance(user, str)) and (user.isdigit() is False): url = f\"https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name={user}&include_rts=true&trim_user=true\" # else go with user ID else: url = f\"https://api.twitter.com/1.1/statuses/user_timeline.json?user_id={user}&include_rts=true&trim_user=true\" response_json = self._manual_request(url) # return the first item since timeline is sorted descending return response_json[0][\"created_at\"] get_relationship Get relationship between two Twitter users. Function: TwitterDataFetcher.get_relationship(source_user: str | int, target_user: str | int) The function takes in a source and a target user identifier. It uses the Tweepy.API.get_friendship function to get the relationship. Therefore, this function handles the performed query based on the provided user identifiers. The function will return the parsed JSON relationship for the source and target user as a dictionary. Source Code def get_relationship(self, source_user: str | int, target_user: str | int) -> dict: \"\"\"Get relationship between two users. Args: user1 (str | int): Source user ID or screen name. user2 (str | int): Target user ID or screen name. Returns: dict: Unpacked tuple of JSON from tweepy Friendship model. Reference: https://developer.twitter.com/en/docs/twitter-api/v1/accounts-and-users/follow-search-get-users/api-reference/get-friendships-show#example-response \"\"\" params = {\"source_id\": None, \"source_screen_name\": None, \"target_id\": None, \"target_screen_name\": None} # if source_user is int or a digit if (isinstance(source_user, int)) or (isinstance(source_user, str) and (source_user.isdigit())): params[\"source_id\"] = source_user # else if screen name was provided elif (isinstance(source_user, str)) and (not source_user.isdigit()): params[\"source_screen_name\"] = source_user else: log.error(\"No ID or username provided for {}\".format(source_user)) # if target_user is int or a digit if (isinstance(target_user, int)) or (isinstance(target_user, str) and (target_user.isdigit())): params[\"target_id\"] = target_user # else if screen name was provided elif (isinstance(target_user, str)) and (not target_user.isdigit()): params[\"target_screen_name\"] = target_user else: log.error(\"No ID or username provided for {}\".format(target_user)) relationship = self.api.get_friendship(**params) return {\"source\": relationship[0]._json, \"target\": relationship[1]._json} get_relationship_pairs Creates pairs for each uniqie combination of provided users based on their relationship. Function: TwitterDataFetcher.get_relationship_pairs(users: List[str | int]) This function takes in a list of user identifiers (i.e., IDs or unique screen names). It will create a pair of each combination of the provided users and returns their individual relationships. For instance, if three users WWU_Muenster , goetheuni , UniKonstanz were provided, the pairs are determined as follows: ( WWU_Muenster , goetheuni ) ( WWU_Muenster , UniKonstanz ) ( goetheuni , WWU_Muenster ) ( goetheuni , UniKonstanz ) ( UniKonstanz , WWU_Muenster ) ( UniKonstanz , goehteuni ) These pairs are set as dictionary keys. The respective relationships are stored as dictionary values. Source Code def get_relationship_pairs(self, users: List[str | int]) -> dict: \"\"\"Creates pairs for each unique combination of provided users based on their relationship. Args: users (List[str | int]): List of user IDs or screen names. Returns: dict: Pairs of users containing their relationship to each other. \"\"\" # init emtpy relationships dict relationships = dict() # iterate over every pair combination of provided users for user in users: for other_user in users: if user != other_user: relationships[(user, other_user)] = self.get_relationship(source_user=user, target_user=other_user) return relationships get_liked_tweets_ids Get (all) liked tweet IDs of the provided user. Function: TwitterDataFetcher.get_liked_tweets_ids(user: str | int, limit: int | None = None) Args: user (str | int): User ID or screen name. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. This function uses the custom TwitterDataFetcher._paginate function to get the specified number of results. To get the tweet IDs, the tweepy.Client.get_liked_tweets function is used. The function wil return a Python set of the IDs of the liked tweets by the user. The function handles the performed request based on what user identifier was given. Source Code def get_liked_tweets_ids(self, user: str | int, limit: int | None = None) -> list(): \"\"\"Get (all) liked Tweets of provided user. Args: user (str | int): User ID or screen name. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. Returns: Set[int]: Tweet Objects of liked Tweets. \"\"\" # if user ID was provided if (isinstance(user, int)) or (user.isdigit()): params = {\"id\": user, \"max_results\": 100, \"pagination_token\": None} else: user_obj = self.get_user_object(user) params = {\"id\": user_obj.id, \"max_results\": 100, \"pagination_token\": None} page_results = self._paginate(self.client.get_liked_tweets, params, limit=limit, page_attribute=\"id\") return page_results get_composed_tweets_ids Get (all) composed tweet IDs of provided user by pagination. Function: TwitterDataFetcher.get_composed_tweets_ids(user: str | int, limit: int | None = None) Args: user (str | int): User ID or screen name. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. This function uses the custom TwitterDataFetcher._paginate function to get the specified number of results. To get the tweet IDs, the tweepy.Client.get_users_tweets function is used. The function wil return a Python set of the IDs of the composed tweets by the user. The function handles the performed request based on what user identifier was given. Source Code def get_composed_tweets_ids(self, user: str | int, limit: int | None = None) -> list: \"\"\"Get (all) composed Tweets of provided user by pagination. Args: user (str | int): User ID or screen name. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. Returns: list: Tweet Objects of composed Tweets. \"\"\" # user ID is required, if screen name was provided if (isinstance(user, str)) and (not user.isdigit()): user = self.get_user_object(user).id # set params params = {\"id\": user, \"max_results\": 100, \"pagination_token\": None} # get page results page_results = self._paginate(self.client.get_users_tweets, params, limit=limit, page_attribute=\"id\") return page_results get_botometer_scores Returns bot scores from the Botometer API for the specified Twitter account. Function: TwitterDataFetcher.get_botometer_scores(user: str | int) This function takes in a Twitter account identifier (i.e., ID or unique screen name.) This function relies on the external Botometer API . To use this function, the corresponding RapidAPI secrets need to be provided. See the secrets overview for more details. The function gets the user's timeline first and takes the latest 100 tweets from its timeline. Then, this data is send via the `payload argument of the TwitterDataFetcher._manual_request function using a POST request. Then, the JSON response is returned. Source Code def get_botometer_scores(self, user: str | int) -> dict: \"\"\"Returns bot scores from the Botometer API for the specified Twitter user. Args: user (str | int): User ID or screen name. Returns: dict: The raw Botometer scores for the specified user. Reference: https://rapidapi.com/OSoMe/api/botometer-pro/details \"\"\" if (self._x_rapidapi_key is None) or (self._x_rapidapi_host is None): raise ValueError(\"'X_RAPIDAPI_KEY' and 'X_RAPIDAPI_HOST' secrets for Botometer API need to be provided.\") # get user object user_obj = self.get_user_object(user) # get user timeline timeline = list(map(lambda x: x._json, self.api.user_timeline(user_id=user_obj.id, count=200))) # get user data if timeline: user_data = timeline[0][\"user\"] else: user_data = user_obj._json screen_name = \"@\" + user_data[\"screen_name\"] # get latest 100 Tweets tweets = list(map(lambda x: x._json, self.api.search_tweets(screen_name, count=100))) # set payload payload = {\"mentions\": tweets, \"timeline\": timeline, \"user\": user_data} # set header headers = {\"content-type\": \"application/json\", \"X-RapidAPI-Key\": self._x_rapidapi_key, \"X-RapidAPI-Host\": self._x_rapidapi_host} # set url url = \"https://botometer-pro.p.rapidapi.com/4/check_account\" # get results response = self._manual_request(url, \"POST\", headers, payload) return response Tweet related methods get_tweet_object Request Twitter tweet object via tweepy. Function: TwitterDataFetcher.get_tweet_object(tweet: str | int) The function takes in either the tweet ID as string or integer. It returns the extended tweet object requested via the API v1 using the tweepy.API.get_status function. If the requested tweet object has been deleted, an error will be returned and a messeage will be logged to stdout. Reference: https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet Source Code def get_tweet_object(self, tweet: str | int) -> tweepy.models.Status: \"\"\"Request Twitter Tweet Object via tweepy Args: tweet (int | str): Tweet ID Returns: tweepy.models.Status: tweepy Status Model Reference: https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet \"\"\" try: tweet_obj = self.api.get_status(tweet, include_entities=True, tweet_mode=\"extended\") except tweepy.errors.NotFound as e: log.error(\"404 Not Found: Resource not found.\") raise e except tweepy.errors.Forbidden as e: log.error(\"403 Forbidden: access refused or access is not allowed.\") raise e return tweet_obj get_liking_users_ids Get (all) liking users of provided tweet by pagination. Function: TwitterDataFetcher.get_liking_users_ids(tweet_id: str | int, limit: int | None = None) Args: tweet (str | int): Tweet ID. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. The function takes in the tweet ID as string or integer representation as well as the limit argument. If limit is none, all available results will be returned. It returns the user IDs of the users that liked the specified tweet. This function uses the custom TwitterDataFetcher._paginate function to get the specified number of results. To get the user IDs, the tweepy.Client.get_liking_users function is used. Source Code def get_liking_users_ids(self, tweet_id: str | int, limit: int | None = None) -> list: \"\"\"Get (all) liking users of provided Tweet by pagination. Args: tweet (str | int): Tweet ID. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. Returns: Set[int]: User Objects as list. \"\"\" # set params params = {\"id\": tweet_id, \"max_results\": 100, \"pagination_token\": None} # get page results page_results = self._paginate(self.client.get_liking_users, params, limit=limit, page_attribute=\"id\") return page_results get_retweeters_ids Get (all) retweeting users of provided tweet by pagination. Function: TwitterDataFetcher.get_retweeters_ids(tweet_id: str | int, limit: int | None = None) Args: tweet (str | int): Tweet ID. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. The function takes in the tweet ID as string or integer representation as well as the limit argument. If limit is none, all available results will be returned. It returns the user IDs of the users that retweeted the specified tweet. This function uses the custom TwitterDataFetcher._paginate function to get the specified number of results. To get the user IDs, the tweepy.Client.get_retweeters function is used. Source Code def get_retweeters_ids(self, tweet_id: str | int, limit: int | None = None) -> list: \"\"\"Get (all) retweeting users of provided Tweet by pagination. Args: tweet (str | int): Tweet ID. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. Returns: Set[int]: User Objects of retweeting users. \"\"\" params = {\"id\": tweet_id, \"max_results\": 100, \"pagination_token\": None} # get page results page_results = self._paginate(self.client.get_retweeters, params, limit=limit, page_attribute=\"id\") return page_results get_quoting_users_ids Get (all) quoting users of provided Tweet by pagination. Function: TwitterDataFetcher.get_quoting_users_ids(tweet_id: str | int, limit: int | None = None) Args: tweet_id (str | int): Tweet ID. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. The function takes in the tweet ID as string or integer representation as well as the limit argument. If limit is none, all available results will be returned. It returns the user IDs of the users that quoted the specified tweet. This function uses the custom TwitterDataFetcher._paginate function to get the specified number of results. To get the tweet objects, the tweepy.Client.get_quote_tweets function is used. Then, the quoting users IDs are extracted from the additional information provided within the includes fields of each page. For more details, see the instructions on the TwitterDataFetcher._paginate function Source Code def get_quoting_users_ids(self, tweet_id: str | int, limit: int | None = None) -> list: \"\"\"Get (all) quoting users of provided Tweet by pagination. Args: tweet_id (str | int): Tweet ID. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. Returns: list: User Objects of quoting users. \"\"\" params = {\"id\": tweet_id, \"max_results\": 100, \"pagination_token\": None} # get page results page_results = self._paginate(self.client.get_quote_tweets, params, limit=limit, response_attribute=\"includes\", page_attribute=\"id\") return page_results get_context_annotations_and_entities Get context annotations and entities from a tweet object. Function: TwitterDataFetcher.get_context_annotations_and_entities(tweet_id: str | int) The function takes in the tweet ID as string or integer representation. The function returns the context annotations (e.g., topics) and named entities of the specified tweet. Therefore, it uses the TwitterDataFetcher._manual_request function. The tweet fields for context_annotations and entities are set. If any context annotation or named entity exist, the JSON response of the request is returned, else None . Reference: https://developer.twitter.com/en/docs/twitter-api/annotations/overview Source Code def get_context_annotations_and_entities(self, tweet_id: str | int) -> dict | None: \"\"\"Get context annotations and entities from a Tweet. Args: tweet_id (str | int): Tweet ID Returns: dict | None: context annotations and entities if available, else None. Reference: https://developer.twitter.com/en/docs/twitter-api/annotations/overview \"\"\" url = f\"https://api.twitter.com/2/tweets/{tweet_id}\" response_json = self._manual_request(url, additional_fields={\"tweet.fields\": [\"context_annotations\", \"entities\"]}) # if key is not awailable, return None if \"context_annotations\" or \"entities\" in response_json[\"data\"]: return response_json[\"data\"] else: return None get_public_metrics Get public metrics from tweet object. Function: TwitterDataFetcher.get_public_metrics(tweet_id: str | int) The function takes in the tweet ID as string or integer representation. The following public metrics are returned: - impressions_count (=views) - quote_count - reply_count - retweet_count - favorite_count (=likes) Here you can find an interpretation of the metrics: https://developer.twitter.com/en/docs/twitter-api/metrics The function returns the public metrics of the tweet. Therefore, it uses the TwitterDataFetcher._manual_request function. The tweet field for public_metrics is set. If any context annotation or named entity exist, the JSON response of the request is returned, else None . Source Code def get_public_metrics(self, tweet_id: str | int) -> dict: \"\"\"Get public metrics from Tweet Object Args: tweet_id (str | int): Tweet ID Returns: dict: Available public metrics for specified Tweet. Metrics: - impressions_count (=views) - quote_count - reply_count - retweet_count - favorite_count (=likes) Reference: https://developer.twitter.com/en/docs/twitter-api/metrics \"\"\" # set URL url = f\"https://api.twitter.com/2/tweets/{tweet_id}\" # make request response_json = self._manual_request(url, additional_fields={\"tweet.fields\": [\"public_metrics\"]}) # get public metrics from JSON response public_metrics = response_json[\"data\"][\"public_metrics\"] return public_metrics","title":"TwitterDataFetcher"},{"location":"maintenance/TwitterDataFetcher/#twitterdatafetcher","text":"The TwitterDataFetcher class is used to specifically query Twitter data. To simplify the queries to the Twitter API, this software component uses already existing open-source software for interacting with the API, namely the Tweepy Python package . It uses the Tweepy Client class to query the data dictionaries of the Twitter Search API v2 as well as the Tweepy API class to access the data dictionaries based on the Twitter Search API v1. The Twitter Search API v1 is mainly used to query user and tweet objects. Although this API version is partially deprecated, it offers a comparable content to the latest API version and often requires less API calls to receive the same information compared to the v2 API. Additional direct requests to the Twitter Search API v2 are performed, too, using the Python requests library to query endpoints that have been migrated or deprecated in the Tweepy package. This class can also be used to in isolation to collect Twitter data. It requires, therefore, authentication for the Twitter platform. Provide the secrets for the Twitter API and, if desired, for the Botometer API. You can find a list of required secrets in the user guide for the TwitterAPI class. This class has the concern to fetch Twitter data. No further processing is performed within this class.","title":"TwitterDataFetcher"},{"location":"maintenance/TwitterDataFetcher/#initialization","text":"If you want to use this class for data processing or other package components, follow the steps below. Import the TwitterDataFetcher class from the fetch module. from pysna.fetch import TwitterDataFetcher fetcher = TwitterDataFetcher( bearer_token: Any | None = None, consumer_key: Any | None = None, consumer_secret: Any | None = None, access_token: Any | None = None, access_token_secret: Any | None = None, x_rapidapi_key: Any | None = None, x_rapidapi_host: Any | None = None ) and invoke a function: user_id = 123450897612 fetcher.get_latest_activity(user_id) Find the necessary secrets on the user guide instructions .","title":"Initialization"},{"location":"maintenance/TwitterDataFetcher/#methods","text":"","title":"Methods"},{"location":"maintenance/TwitterDataFetcher/#private-methods","text":"","title":"Private Methods"},{"location":"maintenance/TwitterDataFetcher/#manual_request","text":"Performs a manual request to the Twitter API. Returns JSON formatted API response. Function: TwitterDataFetcher._manual_request(url: str, method: str = \"GET\", header: dict | None = None, payload: dict | None = None, additional_fields: Dict[str, List[str]] | None = None) Args: url (str): API URL (without specified fields) method (str): Request method according to REST. Defaults to \"GET\". header : Custom HTTP Header. Defaults to None. payload : JSON data for HTTP requests. Defaults to None. additional_fields (Dict[str, List[str]] | None, optional): Fields can be specified (e.g., tweet.fields) according to the official API reference. Defaults to None. The function will raise an exception if the response status code is unlike 200. With this function, performig manual requests is facilitated as the query string is built by the function based on the provided input arguments. The url argument has to be provided in raw form (i.e., without any parameters or fields). The method argument allows to specify the REST request method (i.e., GET, POST, PUT, DELETE). Defaults to GET. The header argument allows to specify a custom header. This is useful if another API besides the Twitter API is fetched. If no custom header is provided, the default header for the Twitter API authentification is used based on the provided bearer_token during instantiation. The payload argument allows to send data for a POST or PUT request. The data must be provided as a dictionary. The additional_fields argument is used to specify Twitter fields (i.e., user fields or tweet fields) and, thus, enhance the query and return additional information. The argument can be used as follows: {\"tweet.fields\": [\"public_metrics\"]} The function will then build the query string and send it to the API. You can find the full list of Twitter fields in the documentation: https://developer.twitter.com/en/docs/twitter-api/fields Source Code def _manual_request(self, url: str, method: str = \"GET\", header: dict | None = None, payload: dict | None = None, additional_fields: Dict[str, List[str]] | None = None) -> dict: \"\"\"Perform a manual request to the Twitter API. Args: url (str): API URL (without specified fields) method (str): Request method according to REST. Defaults to \"GET\". header (dict | None): Custom HTTP Header. Defaults to None. payload (dict | None): JSON data for HTTP requests. Defaults to None. additional_fields (Dict[str, List[str]] | None, optional): Fields can be specified (e.g., tweet.fields) according to the official API reference. Defaults to None. Raises: Exception: If status code != 200. Returns: dict: JSON formatted response of API request. \"\"\" # if additional_fields were provided if additional_fields: # init empty string fields = \"?\" # create fields string dynamically for every field in additional_fields for field in additional_fields.keys(): # e.g., in format \"tweet.fields=lang,author_id\" fields += f\"{field}={','.join(additional_fields[field])}&\" # append fields to url url += fields[:-1] if header is None: # set header header = {\"Authorization\": f\"Bearer {self._bearer_token}\"} response = requests.request(method=method, url=url, headers=header, json=payload) if response.status_code != 200: raise Exception(\"Request returned an error: {} {}\".format(response.status_code, response.text)) return response.json()","title":"manual_request"},{"location":"maintenance/TwitterDataFetcher/#paginate","text":"Custom pagination function It turns out that the pagination functions from the Tweepy Python packge are considerably slower than doing the pagination manually. For this reason, this function was designed. Function: TwitterDataFetcher._paginate(func, params: Dict[str, str | int], limit: int | None = None, response_attribute: str = \"data\", page_attribute: str | None = None) Args: func : Function used for pagination params (Dict[str, str | int]): Dict containing request parameters. Must be of the form {'id': ..., 'limit': ..., 'pagination_token': ...} limit (int | None, optional): Maximum number of results. Defaults to None, thus, no limit. response_attribute (str, optional): Attribute of the Response object. Defaults to \"data\". Options: [\"data\", \"includes\"] page_attribute (str, optional): The attribute that should be extracted for every entry of a page. Defaults to None. The params argument is used to specify the parameters for the next page. Therefore, an id is needed as well as a key indicating the maximm number of results (i.e., limit ). None indicates that no limit is desired and, thus, all available results will be returned. The pagination_token key can be set to None initially. This pagination token will be reset during iteraion. In case, you wish to start from a different page than the first one, provide a pagination token. All parameters must be provided via a dictionary of the form: {\"id\": 1234456, \"limit\": None, # no limit \"pagination_token\": None} The response_attribute argument specifies where to collect the data from the response. If data is specified, the results are received from the default attribute field of the response. If includes is specified, the results are obtained from the additional information provided by the Twitter fields.` The page_attribute argument specifies what attribute should be extracted for every entry of a page. For instance, if this argument is set to id , then the IDs will be extracted from every entry (e.g., user IDs of user objects). Inside that function, a counter is incremented for every result that has been fetched. If the limit was reached, the function will break out the loop and will return immediately the obtained results. Otherwise, the function will check if last page was reached and will fetch the next page (if available). Source Code def _paginate(self, func, params: Dict[str, str | int], limit: int | None = None, response_attribute: str = \"data\", page_attribute: str | None = None) -> list: \"\"\"Pagination function Args: func: Function used for pagination params (Dict[str, str | int]): Dict containing request parameters. Should be of the form {'id': ..., 'max_results': ..., 'pagination_token': ...} limit (int | None, optional): Maximum number of results. Defaults to None, thus, no limit. response_attribute (str, optional): Attribute of the Response object. Defaults to \"data\". Options: [\"data\", \"includes\"] Raises: KeyError: 'id', 'max_results', and 'pagination_token' should be provided in the params dict. Returns: set: Results \"\"\" # init counter counter = 0 # init empty results set results = list() # set break out var break_out = False while not break_out: # make request response = func(**params) # if any data exists if response.__getattribute__(response_attribute) is not None: # iterate over response results for item in response.__getattribute__(response_attribute): # add result if page_attribute is None: results.append(item) else: results.append(item.__getattribute__(page_attribute)) # increment counter counter += 1 # if limit was reached, break if (limit is not None) and (counter == limit): # set break_out var to true break_out = True break # if last page was reached if \"next_token\" not in response.meta: break # else, set new pagination token for next iteration else: params[\"pagination_token\"] = response.meta[\"next_token\"] # if no data exists, break else: break return results","title":"paginate"},{"location":"maintenance/TwitterDataFetcher/#twitter-user-related-methods","text":"","title":"Twitter user related methods"},{"location":"maintenance/TwitterDataFetcher/#get_user_object","text":"Request Twitter user object using Tweepy. The user object is fetched from the Twitter Search API v1. For this, the Tweepy API class is used. Function: TwitterDataFetcher.get_user_object(user: str | int) The function takes in either the user ID as string or integer or the user's unique screen name. It returns the requested API v1 user object. The function handles the performed request based on what user identifier was given. If the requested user has been suspended from Twitter, an error will be returned and a messeage will be logged to stdout. Source Code def get_user_object(self, user: str | int) -> tweepy.models.User: \"\"\"Request Twitter User Object via tweepy Args: user (str): Either User ID or screen name Returns: tweepy.User: Twitter User object from tweepy \"\"\" try: # check if string for user1 is convertible to int in order to check for user ID or screen name if (isinstance(user, int)) or (user.isdigit()): # get profile for user by user ID user_obj = self.api.get_user(user_id=user) else: # get profile for user by screen name user_obj = self.api.get_user(screen_name=user) except tweepy.errors.Forbidden as e: # log to stdout log.error(\"403 Forbidden: access refused or access is not allowed.\") # if user ID was provided if user.isdigit() or isinstance(user, int): url = f\"https://api.twitter.com/2/users/{user}\" else: # if screen name was provided url = f\"https://api.twitter.com/2/users/by/username/{user}\" response = self._manual_request(url) # if an error occured that says the user has been suspended if any(\"User has been suspended\" in error[\"detail\"] for error in response[\"errors\"]): log.error(\"User has been suspended from Twitter. Requested user: {}\".format(user)) raise e else: raise e return user_obj","title":"get_user_object"},{"location":"maintenance/TwitterDataFetcher/#get_user_follower_ids","text":"Request Twitter follower IDs from user. Function: TwitterDataFetcher.get_user_follower_ids(user: str | int) This function takes in a Twitter user identifier (either ID or unique screen name). It returns all follower user IDs from the specified user as a set. Here, the ``tweepy.Cursor```is used for pagination. The function handles the performed request based on what user identifier was given. Source Code def get_user_follower_ids(self, user: str | int) -> Set[int]: \"\"\"Request Twitter follower IDs from user Args: user (str | int): Either User ID or screen name. Returns: Set[int]: Array containing follower IDs \"\"\" # check if string for user1 is convertible to int in order to check for user ID or screen name if (isinstance(user, int)) or (user.isdigit()): params = {\"user_id\": user} else: params = {\"screen_name\": user} follower_ids = list() for page in tweepy.Cursor(self.api.get_follower_ids, **params).pages(): follower_ids.extend(page) return set(follower_ids)","title":"get_user_follower_ids"},{"location":"maintenance/TwitterDataFetcher/#get_user_followee_ids","text":"Request Twitter followee IDs from user. Function: TwitterDataFetcher.get_user_followee_ids(user: str | int) This function takes in a Twitter user identifier (i.e., either ID or unique screen name) and returns a set containing all IDs from the user's followees (AKA friends or follows). The function handles the performed request based on what user identifier was given. Source Code def get_user_followee_ids(self, user: str | int) -> Set[int]: \"\"\"Request Twitter followee IDs from user Args: user (str): Either User ID or screen name. Returns: Set[int]: Array containing follow IDs \"\"\" # check if string for user1 is convertible to int in order to check for user ID or screen name if (isinstance(user, int)) or (user.isdigit()): params = {\"user_id\": user} else: params = {\"screen_name\": user} followee_ids = list() for page in tweepy.Cursor(self.api.get_friend_ids, **params).pages(): followee_ids.extend(page) return set(followee_ids)","title":"get_user_followee_ids"},{"location":"maintenance/TwitterDataFetcher/#get_latest_activity","text":"Returns latest user's activity by fetching the top element from its timeline. Function: TwitterDataFetcher.get_latest_activity(user: str | int) This function takes in a Twitter user identifier (i.e., either ID or unique screen name) and returns the latest activity from the user's timeline. Therefore, the _manual_request function is used to request the corresponding endpoint . Often, this will be a tweet composed by the user itself. Then, all available data of that tweet will be returned as a dictionary. The function handles the performed request based on what user identifier was given. Source Code def get_latest_activity(self, user: str | int) -> dict: \"\"\"Returns latest user's activity by fetching the top element from its timeline. Args: user (str | int): User ID or screen name. Returns: dict: Latest activity. \"\"\" # if screen name was provided if (isinstance(user, str)) and (user.isdigit() is False): url = f\"https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name={user}&include_rts=true&trim_user=true&tweet_mode=extended\" # else go with user ID else: url = f\"https://api.twitter.com/1.1/statuses/user_timeline.json?user_id={user}&include_rts=true&trim_user=true&tweet_mode=extended\" response_json = self._manual_request(url) # return the first item since timeline is sorted descending return response_json[0]","title":"get_latest_activity"},{"location":"maintenance/TwitterDataFetcher/#get_latest_activity_date","text":"Get latest activity date from specified user by fetching the top element from its timeline and extract the creation date. Function: TwitterDataFetcher.get_latest_activity_date(user: str | int) This function takes in a Twitter user identifier (i.e., either ID or unique screen name) and returns the latest activity date from the user's timeline. Therefore, the _manual_request function is used to request the corresponding endpoint . The latest activity date is determined by fetching the latest activity from the user's timeline first, and then extracting the creation date. Usually, this will be a tweet composed by the user. If this is the case, the creation date of that tweet will be returned, representing the latest public available activity date. Source Code def get_latest_activity_date(self, user: str | int) -> str: \"\"\"Get latest activity date from specified user by fetching the top element from its timeline. Args: user (str | int): User ID or screen name. Returns: str: Activity date of latest activity. \"\"\" # if screen name was provided if (isinstance(user, str)) and (user.isdigit() is False): url = f\"https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name={user}&include_rts=true&trim_user=true\" # else go with user ID else: url = f\"https://api.twitter.com/1.1/statuses/user_timeline.json?user_id={user}&include_rts=true&trim_user=true\" response_json = self._manual_request(url) # return the first item since timeline is sorted descending return response_json[0][\"created_at\"]","title":"get_latest_activity_date"},{"location":"maintenance/TwitterDataFetcher/#get_relationship","text":"Get relationship between two Twitter users. Function: TwitterDataFetcher.get_relationship(source_user: str | int, target_user: str | int) The function takes in a source and a target user identifier. It uses the Tweepy.API.get_friendship function to get the relationship. Therefore, this function handles the performed query based on the provided user identifiers. The function will return the parsed JSON relationship for the source and target user as a dictionary. Source Code def get_relationship(self, source_user: str | int, target_user: str | int) -> dict: \"\"\"Get relationship between two users. Args: user1 (str | int): Source user ID or screen name. user2 (str | int): Target user ID or screen name. Returns: dict: Unpacked tuple of JSON from tweepy Friendship model. Reference: https://developer.twitter.com/en/docs/twitter-api/v1/accounts-and-users/follow-search-get-users/api-reference/get-friendships-show#example-response \"\"\" params = {\"source_id\": None, \"source_screen_name\": None, \"target_id\": None, \"target_screen_name\": None} # if source_user is int or a digit if (isinstance(source_user, int)) or (isinstance(source_user, str) and (source_user.isdigit())): params[\"source_id\"] = source_user # else if screen name was provided elif (isinstance(source_user, str)) and (not source_user.isdigit()): params[\"source_screen_name\"] = source_user else: log.error(\"No ID or username provided for {}\".format(source_user)) # if target_user is int or a digit if (isinstance(target_user, int)) or (isinstance(target_user, str) and (target_user.isdigit())): params[\"target_id\"] = target_user # else if screen name was provided elif (isinstance(target_user, str)) and (not target_user.isdigit()): params[\"target_screen_name\"] = target_user else: log.error(\"No ID or username provided for {}\".format(target_user)) relationship = self.api.get_friendship(**params) return {\"source\": relationship[0]._json, \"target\": relationship[1]._json}","title":"get_relationship"},{"location":"maintenance/TwitterDataFetcher/#get_relationship_pairs","text":"Creates pairs for each uniqie combination of provided users based on their relationship. Function: TwitterDataFetcher.get_relationship_pairs(users: List[str | int]) This function takes in a list of user identifiers (i.e., IDs or unique screen names). It will create a pair of each combination of the provided users and returns their individual relationships. For instance, if three users WWU_Muenster , goetheuni , UniKonstanz were provided, the pairs are determined as follows: ( WWU_Muenster , goetheuni ) ( WWU_Muenster , UniKonstanz ) ( goetheuni , WWU_Muenster ) ( goetheuni , UniKonstanz ) ( UniKonstanz , WWU_Muenster ) ( UniKonstanz , goehteuni ) These pairs are set as dictionary keys. The respective relationships are stored as dictionary values. Source Code def get_relationship_pairs(self, users: List[str | int]) -> dict: \"\"\"Creates pairs for each unique combination of provided users based on their relationship. Args: users (List[str | int]): List of user IDs or screen names. Returns: dict: Pairs of users containing their relationship to each other. \"\"\" # init emtpy relationships dict relationships = dict() # iterate over every pair combination of provided users for user in users: for other_user in users: if user != other_user: relationships[(user, other_user)] = self.get_relationship(source_user=user, target_user=other_user) return relationships","title":"get_relationship_pairs"},{"location":"maintenance/TwitterDataFetcher/#get_liked_tweets_ids","text":"Get (all) liked tweet IDs of the provided user. Function: TwitterDataFetcher.get_liked_tweets_ids(user: str | int, limit: int | None = None) Args: user (str | int): User ID or screen name. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. This function uses the custom TwitterDataFetcher._paginate function to get the specified number of results. To get the tweet IDs, the tweepy.Client.get_liked_tweets function is used. The function wil return a Python set of the IDs of the liked tweets by the user. The function handles the performed request based on what user identifier was given. Source Code def get_liked_tweets_ids(self, user: str | int, limit: int | None = None) -> list(): \"\"\"Get (all) liked Tweets of provided user. Args: user (str | int): User ID or screen name. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. Returns: Set[int]: Tweet Objects of liked Tweets. \"\"\" # if user ID was provided if (isinstance(user, int)) or (user.isdigit()): params = {\"id\": user, \"max_results\": 100, \"pagination_token\": None} else: user_obj = self.get_user_object(user) params = {\"id\": user_obj.id, \"max_results\": 100, \"pagination_token\": None} page_results = self._paginate(self.client.get_liked_tweets, params, limit=limit, page_attribute=\"id\") return page_results","title":"get_liked_tweets_ids"},{"location":"maintenance/TwitterDataFetcher/#get_composed_tweets_ids","text":"Get (all) composed tweet IDs of provided user by pagination. Function: TwitterDataFetcher.get_composed_tweets_ids(user: str | int, limit: int | None = None) Args: user (str | int): User ID or screen name. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. This function uses the custom TwitterDataFetcher._paginate function to get the specified number of results. To get the tweet IDs, the tweepy.Client.get_users_tweets function is used. The function wil return a Python set of the IDs of the composed tweets by the user. The function handles the performed request based on what user identifier was given. Source Code def get_composed_tweets_ids(self, user: str | int, limit: int | None = None) -> list: \"\"\"Get (all) composed Tweets of provided user by pagination. Args: user (str | int): User ID or screen name. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. Returns: list: Tweet Objects of composed Tweets. \"\"\" # user ID is required, if screen name was provided if (isinstance(user, str)) and (not user.isdigit()): user = self.get_user_object(user).id # set params params = {\"id\": user, \"max_results\": 100, \"pagination_token\": None} # get page results page_results = self._paginate(self.client.get_users_tweets, params, limit=limit, page_attribute=\"id\") return page_results","title":"get_composed_tweets_ids"},{"location":"maintenance/TwitterDataFetcher/#get_botometer_scores","text":"Returns bot scores from the Botometer API for the specified Twitter account. Function: TwitterDataFetcher.get_botometer_scores(user: str | int) This function takes in a Twitter account identifier (i.e., ID or unique screen name.) This function relies on the external Botometer API . To use this function, the corresponding RapidAPI secrets need to be provided. See the secrets overview for more details. The function gets the user's timeline first and takes the latest 100 tweets from its timeline. Then, this data is send via the `payload argument of the TwitterDataFetcher._manual_request function using a POST request. Then, the JSON response is returned. Source Code def get_botometer_scores(self, user: str | int) -> dict: \"\"\"Returns bot scores from the Botometer API for the specified Twitter user. Args: user (str | int): User ID or screen name. Returns: dict: The raw Botometer scores for the specified user. Reference: https://rapidapi.com/OSoMe/api/botometer-pro/details \"\"\" if (self._x_rapidapi_key is None) or (self._x_rapidapi_host is None): raise ValueError(\"'X_RAPIDAPI_KEY' and 'X_RAPIDAPI_HOST' secrets for Botometer API need to be provided.\") # get user object user_obj = self.get_user_object(user) # get user timeline timeline = list(map(lambda x: x._json, self.api.user_timeline(user_id=user_obj.id, count=200))) # get user data if timeline: user_data = timeline[0][\"user\"] else: user_data = user_obj._json screen_name = \"@\" + user_data[\"screen_name\"] # get latest 100 Tweets tweets = list(map(lambda x: x._json, self.api.search_tweets(screen_name, count=100))) # set payload payload = {\"mentions\": tweets, \"timeline\": timeline, \"user\": user_data} # set header headers = {\"content-type\": \"application/json\", \"X-RapidAPI-Key\": self._x_rapidapi_key, \"X-RapidAPI-Host\": self._x_rapidapi_host} # set url url = \"https://botometer-pro.p.rapidapi.com/4/check_account\" # get results response = self._manual_request(url, \"POST\", headers, payload) return response","title":"get_botometer_scores"},{"location":"maintenance/TwitterDataFetcher/#tweet-related-methods","text":"","title":"Tweet related methods"},{"location":"maintenance/TwitterDataFetcher/#get_tweet_object","text":"Request Twitter tweet object via tweepy. Function: TwitterDataFetcher.get_tweet_object(tweet: str | int) The function takes in either the tweet ID as string or integer. It returns the extended tweet object requested via the API v1 using the tweepy.API.get_status function. If the requested tweet object has been deleted, an error will be returned and a messeage will be logged to stdout. Reference: https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet Source Code def get_tweet_object(self, tweet: str | int) -> tweepy.models.Status: \"\"\"Request Twitter Tweet Object via tweepy Args: tweet (int | str): Tweet ID Returns: tweepy.models.Status: tweepy Status Model Reference: https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet \"\"\" try: tweet_obj = self.api.get_status(tweet, include_entities=True, tweet_mode=\"extended\") except tweepy.errors.NotFound as e: log.error(\"404 Not Found: Resource not found.\") raise e except tweepy.errors.Forbidden as e: log.error(\"403 Forbidden: access refused or access is not allowed.\") raise e return tweet_obj","title":"get_tweet_object"},{"location":"maintenance/TwitterDataFetcher/#get_liking_users_ids","text":"Get (all) liking users of provided tweet by pagination. Function: TwitterDataFetcher.get_liking_users_ids(tweet_id: str | int, limit: int | None = None) Args: tweet (str | int): Tweet ID. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. The function takes in the tweet ID as string or integer representation as well as the limit argument. If limit is none, all available results will be returned. It returns the user IDs of the users that liked the specified tweet. This function uses the custom TwitterDataFetcher._paginate function to get the specified number of results. To get the user IDs, the tweepy.Client.get_liking_users function is used. Source Code def get_liking_users_ids(self, tweet_id: str | int, limit: int | None = None) -> list: \"\"\"Get (all) liking users of provided Tweet by pagination. Args: tweet (str | int): Tweet ID. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. Returns: Set[int]: User Objects as list. \"\"\" # set params params = {\"id\": tweet_id, \"max_results\": 100, \"pagination_token\": None} # get page results page_results = self._paginate(self.client.get_liking_users, params, limit=limit, page_attribute=\"id\") return page_results","title":"get_liking_users_ids"},{"location":"maintenance/TwitterDataFetcher/#get_retweeters_ids","text":"Get (all) retweeting users of provided tweet by pagination. Function: TwitterDataFetcher.get_retweeters_ids(tweet_id: str | int, limit: int | None = None) Args: tweet (str | int): Tweet ID. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. The function takes in the tweet ID as string or integer representation as well as the limit argument. If limit is none, all available results will be returned. It returns the user IDs of the users that retweeted the specified tweet. This function uses the custom TwitterDataFetcher._paginate function to get the specified number of results. To get the user IDs, the tweepy.Client.get_retweeters function is used. Source Code def get_retweeters_ids(self, tweet_id: str | int, limit: int | None = None) -> list: \"\"\"Get (all) retweeting users of provided Tweet by pagination. Args: tweet (str | int): Tweet ID. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. Returns: Set[int]: User Objects of retweeting users. \"\"\" params = {\"id\": tweet_id, \"max_results\": 100, \"pagination_token\": None} # get page results page_results = self._paginate(self.client.get_retweeters, params, limit=limit, page_attribute=\"id\") return page_results","title":"get_retweeters_ids"},{"location":"maintenance/TwitterDataFetcher/#get_quoting_users_ids","text":"Get (all) quoting users of provided Tweet by pagination. Function: TwitterDataFetcher.get_quoting_users_ids(tweet_id: str | int, limit: int | None = None) Args: tweet_id (str | int): Tweet ID. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. The function takes in the tweet ID as string or integer representation as well as the limit argument. If limit is none, all available results will be returned. It returns the user IDs of the users that quoted the specified tweet. This function uses the custom TwitterDataFetcher._paginate function to get the specified number of results. To get the tweet objects, the tweepy.Client.get_quote_tweets function is used. Then, the quoting users IDs are extracted from the additional information provided within the includes fields of each page. For more details, see the instructions on the TwitterDataFetcher._paginate function Source Code def get_quoting_users_ids(self, tweet_id: str | int, limit: int | None = None) -> list: \"\"\"Get (all) quoting users of provided Tweet by pagination. Args: tweet_id (str | int): Tweet ID. limit (int | None): The maximum number of results to be returned. By default, each page will return the maximum number of results available. Returns: list: User Objects of quoting users. \"\"\" params = {\"id\": tweet_id, \"max_results\": 100, \"pagination_token\": None} # get page results page_results = self._paginate(self.client.get_quote_tweets, params, limit=limit, response_attribute=\"includes\", page_attribute=\"id\") return page_results","title":"get_quoting_users_ids"},{"location":"maintenance/TwitterDataFetcher/#get_context_annotations_and_entities","text":"Get context annotations and entities from a tweet object. Function: TwitterDataFetcher.get_context_annotations_and_entities(tweet_id: str | int) The function takes in the tweet ID as string or integer representation. The function returns the context annotations (e.g., topics) and named entities of the specified tweet. Therefore, it uses the TwitterDataFetcher._manual_request function. The tweet fields for context_annotations and entities are set. If any context annotation or named entity exist, the JSON response of the request is returned, else None . Reference: https://developer.twitter.com/en/docs/twitter-api/annotations/overview Source Code def get_context_annotations_and_entities(self, tweet_id: str | int) -> dict | None: \"\"\"Get context annotations and entities from a Tweet. Args: tweet_id (str | int): Tweet ID Returns: dict | None: context annotations and entities if available, else None. Reference: https://developer.twitter.com/en/docs/twitter-api/annotations/overview \"\"\" url = f\"https://api.twitter.com/2/tweets/{tweet_id}\" response_json = self._manual_request(url, additional_fields={\"tweet.fields\": [\"context_annotations\", \"entities\"]}) # if key is not awailable, return None if \"context_annotations\" or \"entities\" in response_json[\"data\"]: return response_json[\"data\"] else: return None","title":"get_context_annotations_and_entities"},{"location":"maintenance/TwitterDataFetcher/#get_public_metrics","text":"Get public metrics from tweet object. Function: TwitterDataFetcher.get_public_metrics(tweet_id: str | int) The function takes in the tweet ID as string or integer representation. The following public metrics are returned: - impressions_count (=views) - quote_count - reply_count - retweet_count - favorite_count (=likes) Here you can find an interpretation of the metrics: https://developer.twitter.com/en/docs/twitter-api/metrics The function returns the public metrics of the tweet. Therefore, it uses the TwitterDataFetcher._manual_request function. The tweet field for public_metrics is set. If any context annotation or named entity exist, the JSON response of the request is returned, else None . Source Code def get_public_metrics(self, tweet_id: str | int) -> dict: \"\"\"Get public metrics from Tweet Object Args: tweet_id (str | int): Tweet ID Returns: dict: Available public metrics for specified Tweet. Metrics: - impressions_count (=views) - quote_count - reply_count - retweet_count - favorite_count (=likes) Reference: https://developer.twitter.com/en/docs/twitter-api/metrics \"\"\" # set URL url = f\"https://api.twitter.com/2/tweets/{tweet_id}\" # make request response_json = self._manual_request(url, additional_fields={\"tweet.fields\": [\"public_metrics\"]}) # get public metrics from JSON response public_metrics = response_json[\"data\"][\"public_metrics\"] return public_metrics","title":"get_public_metrics"},{"location":"maintenance/TwitterDataProcessor/","text":"TwitterDataProcessor The TwitterDataProcessor has the purpose to process Twitter-specific data and respective data dictionaries (i.e., user or tweet data dictionaries). This class is used inside the TwitterAPI class as a component class through composition. This class can also be used to process previously collected data. It requires no authentication for the Twitter platform and, thus, can be used in isolation. This class has a separated concern compared to the other package's classes, namely to process Twitter-related data. Initialization If you want to use this class for data processing or other package components, follow the steps below. Import the TwitterDataProcessor class from the process module. from pysna.process import TwitterDataProcessor data_processor = TwitterDataProcessor() and invoke a function: tweet = \"Savage Love \ud83c\udfb6 #SavageLoveRemix\" data_processor.clean_tweet(tweet) Methods extract_followers Extract IDs, names, and screen names from a user's followers. This function takes in a Tweepy user object from the v1 API version and returns a dictionary containing the extracted information. Function: TwitterDataProcessor.extract_followers(user_object: tweepy.User) This function will return a dictionary of the form {\"followers_ids\": [], \"followers_names\": [], \"followers_screen_names\": []} NOTE : This function needs a recently fetched Twitter user object from the API v1. Stored user objects (e.g., using the pickle module) that are to be analyzed later will lead to an error. Source Code def extract_followers(self, user_object: tweepy.User) -> Dict[str, str | int]: \"\"\"Extract IDs, names, and screen names from a user's followers. Args: user_object (tweepy.User): Tweepy User Object. Returns: Dict[str, str | int]: Dictionary containing IDs, names, and screen names. \"\"\" info = {\"followers_ids\": list(), \"followers_names\": list(), \"followers_screen_names\": list()} # extract follower IDs info[\"followers_ids\"] = user_object.follower_ids() # extract names and screen names for follower in user_object.followers(): info[\"followers_names\"].append(follower.name) info[\"followers_screen_names\"].append(follower.screen_name) return info extract_followees Extract IDs, names, and screen names from a user's followees (i.e., their follows). This function takes in a Tweepy user object from the v1 API version and returns a dictionary containing the extracted information. Function: TwitterDataProcessor.extract_followees(user_object: tweepy.User) This function will return a dictionary of the form {\"followees_ids\": [], \"followees_names\": [], \"followees_screen_names\": []} NOTE : This function needs a recently fetched Twitter user object from the API v1. Stored user objects (e.g., using the pickle module) that are to be analyzed later will lead to an error. Source Code def extract_followees(self, user_object: tweepy.User) -> Dict[str, str | int]: \"\"\"Extract IDs, names, and screen names from a user's followees. Args: user_object (tweepy.User): Tweepy User Object. Returns: Dict[str, str | int]: Dictionary containing IDs, names, and screen names. \"\"\" info = {\"followees_ids\": list(), \"followees_names\": list(), \"followees_screen_names\": list()} # extract IDs, names and screen names for followee in user_object.friends(): info[\"followees_ids\"].append(followee.id) info[\"followees_names\"].append(followee.name) info[\"followees_screen_names\"].append(followee.screen_name) return info clean_tweet Utility function to clean tweet text by removing links, special characters using simple regex statements. It takes in the raw text of a tweet. Function: TwitterDataProcessor.clean_tweet(tweet: str) This function is used before the detect_tweet_sentiment function. Thus, the tweet is cleaned first and then its sentiment is determined. Both functions are used in combination within the TwitterAPI class. Source Code def clean_tweet(self, tweet: str) -> str: \"\"\"Utility function to clean tweet text by removing links, special characters using simple regex statements. Args: tweet (str): Raw text of the Tweet. Returns: str: Cleaned Tweet \"\"\" return \" \".join(re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) detect_tweet_sentiment Utility function to classify sentiment of passed tweet using vader sentiment analyzer. English Tweets only. The function takes in the text of a tweet (cleaned from special characters, linkes, emojis, etc.) and will return the tweet sentiment as well as the polarity scores. Function: TwitterDataProcessor.detect_tweet_sentiment(tweet: str) For sentiment detection, the Vader sentiment analyzer is used as this one turned out to be more accurate for tweets compared to NLTK sentiment analyzers. The function will return a dictionary containing the label of the sentiment (i.e., positive, neutral, or negative) and the polarity scores: {\"label\": label, \"polarity_scores\": polarity_score} Source Code def detect_tweet_sentiment(self, tweet: str) -> dict: \"\"\"Utility function to classify sentiment of passed tweet using textblob's sentiment method. English Tweets only. Args: tweet (str): The raw text of the Tweet. Returns: str: the sentiment of the Tweet (either positive, neutral, or negative) and the polarity scores. \"\"\" # create VADER instance analyser = SentimentIntensityAnalyzer() # get polarity scores from cleaned tweet polarity_scores = analyser.polarity_scores(self.clean_tweet(tweet)) # define label if polarity_scores[\"compound\"] >= 0.05: label = \"positive\" elif polarity_scores[\"compound\"] <= -0.05: label = \"negative\" else: label = \"neutral\" # return label and polarity scores return {\"label\": label, \"polarity_scores\": polarity_scores} calc_similarity This function is used to calculate the similarity between multiple user or tweet objects. The function takes in either a list of user objects or a list of public tweet metrics as well as a features list. Either user objects or tweet metrics need to be provided, not both. The user objects must be recently fetched from the Twitter API v1. A stored object (e.g., by using the pickle Python module) will not have the necessary properties to be resolved by this function. Otherwise, an error will be returned. The similarity is calculated based on a feature vector containing numeric values. Thus, for a given set of user or tweet attributes, the features must be provided on which the similarity will be computed. As a distance measure and, thus, the similarity of feature vectors, the vector norm of second order will be calculated which is equivalent to the euclidean distance. Therefore, the numpy.linalg.norm function is used. The smaller the distance, the more similar the two vectors are. The function will determine the distance between a distinct pair of user or tweet objects. For instance, when three user objects for the Twitter accounts 12355 , 734231 , 9083468 are provided, the following output will be generated: {(12355, 734231): 4567.098, (12355, 9083468): 5980.076, (734231, 9083468): 8763.32} The output dictionary contains the distinct pairs of objects as a tuple as dictionary keys. The distances for each distinct pair is given as dictionary value. The output is sorted in ascending order. Hence, the minimal distance and, thus, the most similar pair is provided as first dictionary entry. Function: TwitterDataProcessor.calc_similarity(user_objs: List[dict] | None = None, tweet_metrics: List[Dict[int, dict]] | None = None, *, features: List[str]) Args: user_objs (List[dict] | None, optional): List of serialized Twitter user objects from Twitter Search API v1. Defaults to None. tweet_metrics (List[Dict[int | dict]] | None, optional): List of public Tweet metrics as dictionaries with Tweet IDs as keys. Defaults to None. features (List[str]): Features that should be contained in the feature vector. Features have to be numeric and must belong to the respective object (i.e., user or tweet.) The features that can be provided for the features list can be found in the detailed description of the attributes for the compare_tweets function and the detailed description of the attributes for the compare_users function . The implementation design of this function allows a comparison of Twitter users or tweets based on the available metrics. The implementation was inspired by the characterics of social bots on Twitter as they often have a similar number of followers or followees and their posted tweets often have a similar number of likes. Thus, the calculated similarities might help to identify bot-like behavior of Twitter accounts as well as identify deviations from normal Twitter accounts. If their similarities are small, they are likely to have a similar behavior on Twitter (i.e., a bot could be analyzed). Source Code def calc_similarity(self, user_objs: List[dict] | None = None, tweet_metrics: List[Dict[int, dict]] | None = None, *, features: List[str]) -> dict: \"\"\"Calculates the euclidean distance of users/tweets based on a feature vector. Either user objects or Tweet objects must be specified, not both. Args: user_objs (List[dict] | None, optional): List of serialized Twitter user objects from Twitter Search API v1. Defaults to None. tweet_metrics (List[Dict[int | dict]] | None, optional): List of public Tweet metrics as dictionaries with Tweet IDs as keys. Defaults to None. features (List[str]): Features that should be contained in the feature vector. Features have to be numeric and must belong to the respective object (i.e., user or tweet.) Raises: ValueError: If either 'user_objs' and 'tweet_objs' or none of them were provided. AssertionError: If non-numeric feature was provided in the 'features' list. Returns: dict: Unique pair of users/tweets containing the respective euclidean distance. Sorted in ascending order. \"\"\" # init empty dict to store distances distances = dict() # if users and tweets were provided if user_objs and tweet_metrics: raise ValueError(\"Either 'user_objs' or 'tweet_metrics' must be specified, not both.\") # if only user_objs were provided elif user_objs: # iterate over every uniqe pair for i in range(len(user_objs)): for j in range(i + 1, len(user_objs)): # get user objects for each pair user_i = user_objs[i] user_j = user_objs[j] # build feature vector vec_i = np.array([user_i[feature] for feature in features]) vec_j = np.array([user_j[feature] for feature in features]) # feature vectors have to contain numeric values assert all(isinstance(feat, Number) for feat in vec_i), \"only numeric features are allowed\" assert all(isinstance(feat, Number) for feat in vec_j), \"only numeric features are allowed\" # calc euclidean distance distances[(user_i[\"id\"], user_j[\"id\"])] = np.linalg.norm(vec_i - vec_j, ord=2) elif tweet_metrics: # iterate over every uniqe pair for i in range(len(tweet_metrics)): for j in range(i + 1, len(tweet_metrics)): # get Tweet objects for each pair tweet_i = list(tweet_metrics.values())[i] tweet_j = list(tweet_metrics.values())[j] # build feature vector vec_i = np.array([tweet_i[feature] for feature in features]) vec_j = np.array([tweet_j[feature] for feature in features]) # feature vectors have to contain numeric values assert all(isinstance(feat, Number) for feat in vec_i), \"only numeric features are allowed\" assert all(isinstance(feat, Number) for feat in vec_j), \"only numeric features are allowed\" # calc euclidean distance distances[(list(tweet_metrics.keys())[i], list(tweet_metrics.keys())[j])] = np.linalg.norm(vec_i - vec_j, ord=2) # if none was provided else: raise ValueError(\"Either 'user_objs' or 'tweet_metrics' must be provided.\") # sort dict in ascendin order sorted_values = dict(sorted(distances.items(), key=operator.itemgetter(1))) return sorted_values","title":"TwitterDataProcessor"},{"location":"maintenance/TwitterDataProcessor/#twitterdataprocessor","text":"The TwitterDataProcessor has the purpose to process Twitter-specific data and respective data dictionaries (i.e., user or tweet data dictionaries). This class is used inside the TwitterAPI class as a component class through composition. This class can also be used to process previously collected data. It requires no authentication for the Twitter platform and, thus, can be used in isolation. This class has a separated concern compared to the other package's classes, namely to process Twitter-related data.","title":"TwitterDataProcessor"},{"location":"maintenance/TwitterDataProcessor/#initialization","text":"If you want to use this class for data processing or other package components, follow the steps below. Import the TwitterDataProcessor class from the process module. from pysna.process import TwitterDataProcessor data_processor = TwitterDataProcessor() and invoke a function: tweet = \"Savage Love \ud83c\udfb6 #SavageLoveRemix\" data_processor.clean_tweet(tweet)","title":"Initialization"},{"location":"maintenance/TwitterDataProcessor/#methods","text":"","title":"Methods"},{"location":"maintenance/TwitterDataProcessor/#extract_followers","text":"Extract IDs, names, and screen names from a user's followers. This function takes in a Tweepy user object from the v1 API version and returns a dictionary containing the extracted information. Function: TwitterDataProcessor.extract_followers(user_object: tweepy.User) This function will return a dictionary of the form {\"followers_ids\": [], \"followers_names\": [], \"followers_screen_names\": []} NOTE : This function needs a recently fetched Twitter user object from the API v1. Stored user objects (e.g., using the pickle module) that are to be analyzed later will lead to an error. Source Code def extract_followers(self, user_object: tweepy.User) -> Dict[str, str | int]: \"\"\"Extract IDs, names, and screen names from a user's followers. Args: user_object (tweepy.User): Tweepy User Object. Returns: Dict[str, str | int]: Dictionary containing IDs, names, and screen names. \"\"\" info = {\"followers_ids\": list(), \"followers_names\": list(), \"followers_screen_names\": list()} # extract follower IDs info[\"followers_ids\"] = user_object.follower_ids() # extract names and screen names for follower in user_object.followers(): info[\"followers_names\"].append(follower.name) info[\"followers_screen_names\"].append(follower.screen_name) return info","title":"extract_followers"},{"location":"maintenance/TwitterDataProcessor/#extract_followees","text":"Extract IDs, names, and screen names from a user's followees (i.e., their follows). This function takes in a Tweepy user object from the v1 API version and returns a dictionary containing the extracted information. Function: TwitterDataProcessor.extract_followees(user_object: tweepy.User) This function will return a dictionary of the form {\"followees_ids\": [], \"followees_names\": [], \"followees_screen_names\": []} NOTE : This function needs a recently fetched Twitter user object from the API v1. Stored user objects (e.g., using the pickle module) that are to be analyzed later will lead to an error. Source Code def extract_followees(self, user_object: tweepy.User) -> Dict[str, str | int]: \"\"\"Extract IDs, names, and screen names from a user's followees. Args: user_object (tweepy.User): Tweepy User Object. Returns: Dict[str, str | int]: Dictionary containing IDs, names, and screen names. \"\"\" info = {\"followees_ids\": list(), \"followees_names\": list(), \"followees_screen_names\": list()} # extract IDs, names and screen names for followee in user_object.friends(): info[\"followees_ids\"].append(followee.id) info[\"followees_names\"].append(followee.name) info[\"followees_screen_names\"].append(followee.screen_name) return info","title":"extract_followees"},{"location":"maintenance/TwitterDataProcessor/#clean_tweet","text":"Utility function to clean tweet text by removing links, special characters using simple regex statements. It takes in the raw text of a tweet. Function: TwitterDataProcessor.clean_tweet(tweet: str) This function is used before the detect_tweet_sentiment function. Thus, the tweet is cleaned first and then its sentiment is determined. Both functions are used in combination within the TwitterAPI class. Source Code def clean_tweet(self, tweet: str) -> str: \"\"\"Utility function to clean tweet text by removing links, special characters using simple regex statements. Args: tweet (str): Raw text of the Tweet. Returns: str: Cleaned Tweet \"\"\" return \" \".join(re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())","title":"clean_tweet"},{"location":"maintenance/TwitterDataProcessor/#detect_tweet_sentiment","text":"Utility function to classify sentiment of passed tweet using vader sentiment analyzer. English Tweets only. The function takes in the text of a tweet (cleaned from special characters, linkes, emojis, etc.) and will return the tweet sentiment as well as the polarity scores. Function: TwitterDataProcessor.detect_tweet_sentiment(tweet: str) For sentiment detection, the Vader sentiment analyzer is used as this one turned out to be more accurate for tweets compared to NLTK sentiment analyzers. The function will return a dictionary containing the label of the sentiment (i.e., positive, neutral, or negative) and the polarity scores: {\"label\": label, \"polarity_scores\": polarity_score} Source Code def detect_tweet_sentiment(self, tweet: str) -> dict: \"\"\"Utility function to classify sentiment of passed tweet using textblob's sentiment method. English Tweets only. Args: tweet (str): The raw text of the Tweet. Returns: str: the sentiment of the Tweet (either positive, neutral, or negative) and the polarity scores. \"\"\" # create VADER instance analyser = SentimentIntensityAnalyzer() # get polarity scores from cleaned tweet polarity_scores = analyser.polarity_scores(self.clean_tweet(tweet)) # define label if polarity_scores[\"compound\"] >= 0.05: label = \"positive\" elif polarity_scores[\"compound\"] <= -0.05: label = \"negative\" else: label = \"neutral\" # return label and polarity scores return {\"label\": label, \"polarity_scores\": polarity_scores}","title":"detect_tweet_sentiment"},{"location":"maintenance/TwitterDataProcessor/#calc_similarity","text":"This function is used to calculate the similarity between multiple user or tweet objects. The function takes in either a list of user objects or a list of public tweet metrics as well as a features list. Either user objects or tweet metrics need to be provided, not both. The user objects must be recently fetched from the Twitter API v1. A stored object (e.g., by using the pickle Python module) will not have the necessary properties to be resolved by this function. Otherwise, an error will be returned. The similarity is calculated based on a feature vector containing numeric values. Thus, for a given set of user or tweet attributes, the features must be provided on which the similarity will be computed. As a distance measure and, thus, the similarity of feature vectors, the vector norm of second order will be calculated which is equivalent to the euclidean distance. Therefore, the numpy.linalg.norm function is used. The smaller the distance, the more similar the two vectors are. The function will determine the distance between a distinct pair of user or tweet objects. For instance, when three user objects for the Twitter accounts 12355 , 734231 , 9083468 are provided, the following output will be generated: {(12355, 734231): 4567.098, (12355, 9083468): 5980.076, (734231, 9083468): 8763.32} The output dictionary contains the distinct pairs of objects as a tuple as dictionary keys. The distances for each distinct pair is given as dictionary value. The output is sorted in ascending order. Hence, the minimal distance and, thus, the most similar pair is provided as first dictionary entry. Function: TwitterDataProcessor.calc_similarity(user_objs: List[dict] | None = None, tweet_metrics: List[Dict[int, dict]] | None = None, *, features: List[str]) Args: user_objs (List[dict] | None, optional): List of serialized Twitter user objects from Twitter Search API v1. Defaults to None. tweet_metrics (List[Dict[int | dict]] | None, optional): List of public Tweet metrics as dictionaries with Tweet IDs as keys. Defaults to None. features (List[str]): Features that should be contained in the feature vector. Features have to be numeric and must belong to the respective object (i.e., user or tweet.) The features that can be provided for the features list can be found in the detailed description of the attributes for the compare_tweets function and the detailed description of the attributes for the compare_users function . The implementation design of this function allows a comparison of Twitter users or tweets based on the available metrics. The implementation was inspired by the characterics of social bots on Twitter as they often have a similar number of followers or followees and their posted tweets often have a similar number of likes. Thus, the calculated similarities might help to identify bot-like behavior of Twitter accounts as well as identify deviations from normal Twitter accounts. If their similarities are small, they are likely to have a similar behavior on Twitter (i.e., a bot could be analyzed). Source Code def calc_similarity(self, user_objs: List[dict] | None = None, tweet_metrics: List[Dict[int, dict]] | None = None, *, features: List[str]) -> dict: \"\"\"Calculates the euclidean distance of users/tweets based on a feature vector. Either user objects or Tweet objects must be specified, not both. Args: user_objs (List[dict] | None, optional): List of serialized Twitter user objects from Twitter Search API v1. Defaults to None. tweet_metrics (List[Dict[int | dict]] | None, optional): List of public Tweet metrics as dictionaries with Tweet IDs as keys. Defaults to None. features (List[str]): Features that should be contained in the feature vector. Features have to be numeric and must belong to the respective object (i.e., user or tweet.) Raises: ValueError: If either 'user_objs' and 'tweet_objs' or none of them were provided. AssertionError: If non-numeric feature was provided in the 'features' list. Returns: dict: Unique pair of users/tweets containing the respective euclidean distance. Sorted in ascending order. \"\"\" # init empty dict to store distances distances = dict() # if users and tweets were provided if user_objs and tweet_metrics: raise ValueError(\"Either 'user_objs' or 'tweet_metrics' must be specified, not both.\") # if only user_objs were provided elif user_objs: # iterate over every uniqe pair for i in range(len(user_objs)): for j in range(i + 1, len(user_objs)): # get user objects for each pair user_i = user_objs[i] user_j = user_objs[j] # build feature vector vec_i = np.array([user_i[feature] for feature in features]) vec_j = np.array([user_j[feature] for feature in features]) # feature vectors have to contain numeric values assert all(isinstance(feat, Number) for feat in vec_i), \"only numeric features are allowed\" assert all(isinstance(feat, Number) for feat in vec_j), \"only numeric features are allowed\" # calc euclidean distance distances[(user_i[\"id\"], user_j[\"id\"])] = np.linalg.norm(vec_i - vec_j, ord=2) elif tweet_metrics: # iterate over every uniqe pair for i in range(len(tweet_metrics)): for j in range(i + 1, len(tweet_metrics)): # get Tweet objects for each pair tweet_i = list(tweet_metrics.values())[i] tweet_j = list(tweet_metrics.values())[j] # build feature vector vec_i = np.array([tweet_i[feature] for feature in features]) vec_j = np.array([tweet_j[feature] for feature in features]) # feature vectors have to contain numeric values assert all(isinstance(feat, Number) for feat in vec_i), \"only numeric features are allowed\" assert all(isinstance(feat, Number) for feat in vec_j), \"only numeric features are allowed\" # calc euclidean distance distances[(list(tweet_metrics.keys())[i], list(tweet_metrics.keys())[j])] = np.linalg.norm(vec_i - vec_j, ord=2) # if none was provided else: raise ValueError(\"Either 'user_objs' or 'tweet_metrics' must be provided.\") # sort dict in ascendin order sorted_values = dict(sorted(distances.items(), key=operator.itemgetter(1))) return sorted_values","title":"calc_similarity"},{"location":"maintenance/cli/","text":"","title":"CLI Function"},{"location":"maintenance/implementation-details/","text":"Implementation Details This package was designed to perform more detailed and advanced queries to the Twitter API and allows a more detailed analysis of Twitter data. Four classes were implemented: TwitterAPI , TwitterDataFetcher , BaseDataProcessor , TwitterDataProcessor The figure below shows the architecture of the PySNA package: PySNA Architecture depicted in UML The TwitterAPI class uses instances of TwitterDataFetcher and TwitterDataProcessor . This class serves as an interface to the user and is the main class of the package. With this class, all functions of the package (except the ones from the utils.py module) can be used. It is built on top of the famous Tweepy Python package. Therefore, it inherits the Tweepy Client class and extends it with the functions provided by this package. During the implementation of this package, the Separation of Concerns design principle was realized. That means, that every class in this package serves a single, well-defined purpose and no interleaving of different procedures exist. Whereas the TwitterDataProcessor class serves the purpose of processing Twitter-related data and the TwitterDataFetcher class is used for fetching social data from the Twitter platform using its API, the TwitterAPI class offers an interface for user interaction. Each class also has a single responsibility. The design principle of making classes and encapuslation ensures that related data and procedures are kept together within one function and/or class. An overview of all attributes and methods of the implemented classes is provided in the following UML diagram: PySNA Class Overview depicted in UML Available content: TwitterAPI TwitterDataFetcher TwitterDataProcessor BaseDataProcessor Utility Functions CLI Functions Software Testing","title":"Implementation details"},{"location":"maintenance/implementation-details/#implementation-details","text":"This package was designed to perform more detailed and advanced queries to the Twitter API and allows a more detailed analysis of Twitter data. Four classes were implemented: TwitterAPI , TwitterDataFetcher , BaseDataProcessor , TwitterDataProcessor The figure below shows the architecture of the PySNA package: PySNA Architecture depicted in UML The TwitterAPI class uses instances of TwitterDataFetcher and TwitterDataProcessor . This class serves as an interface to the user and is the main class of the package. With this class, all functions of the package (except the ones from the utils.py module) can be used. It is built on top of the famous Tweepy Python package. Therefore, it inherits the Tweepy Client class and extends it with the functions provided by this package. During the implementation of this package, the Separation of Concerns design principle was realized. That means, that every class in this package serves a single, well-defined purpose and no interleaving of different procedures exist. Whereas the TwitterDataProcessor class serves the purpose of processing Twitter-related data and the TwitterDataFetcher class is used for fetching social data from the Twitter platform using its API, the TwitterAPI class offers an interface for user interaction. Each class also has a single responsibility. The design principle of making classes and encapuslation ensures that related data and procedures are kept together within one function and/or class. An overview of all attributes and methods of the implemented classes is provided in the following UML diagram: PySNA Class Overview depicted in UML Available content: TwitterAPI TwitterDataFetcher TwitterDataProcessor BaseDataProcessor Utility Functions CLI Functions Software Testing","title":"Implementation Details"},{"location":"maintenance/repository/","text":"","title":"Repository Information"},{"location":"maintenance/testing/","text":"Coming soon...","title":"Software Testing"},{"location":"maintenance/utils/","text":"","title":"Utility Functions"},{"location":"user-guide/installation/","text":"Installation The easiest way to install the latest version from PyPI is by using pip : pip install pysna You can also use Git to clone the repository from GitHub to install the latest development version: git clone https://github.com/mathun3003/PySNA.git cd PySNA pip install . Alternatively, install directly from the GitHub repository: pip install git+https://github.com/mathun3003/PySNA.git","title":"Installation"},{"location":"user-guide/installation/#installation","text":"The easiest way to install the latest version from PyPI is by using pip : pip install pysna You can also use Git to clone the repository from GitHub to install the latest development version: git clone https://github.com/mathun3003/PySNA.git cd PySNA pip install . Alternatively, install directly from the GitHub repository: pip install git+https://github.com/mathun3003/PySNA.git","title":"Installation"},{"location":"user-guide/overview/","text":"Available content: TwitterAPI Utility Functions CLI Tool","title":"Overview"},{"location":"user-guide/quick-start/","text":"Quick Start Import the API class for the Twitter API by writing: from pysna import TwitterAPI or import utility functions, too, by writing: from pysna import * Then, create an API instance by running: api = TwitterAPI(\"BEARER_TOKEN\", \"CONSUMER_KEY\", \"CONSUMER_SECRET\", \"ACCESS_TOKEN\", \"ACCESS_TOKEN_SECRET\") and invoke a function: api.user_info(...) Find usage and output examples in the examples folder .","title":"Quick Start"},{"location":"user-guide/quick-start/#quick-start","text":"Import the API class for the Twitter API by writing: from pysna import TwitterAPI or import utility functions, too, by writing: from pysna import * Then, create an API instance by running: api = TwitterAPI(\"BEARER_TOKEN\", \"CONSUMER_KEY\", \"CONSUMER_SECRET\", \"ACCESS_TOKEN\", \"ACCESS_TOKEN_SECRET\") and invoke a function: api.user_info(...) Find usage and output examples in the examples folder .","title":"Quick Start"},{"location":"user-guide/overview/TwitterAPI/","text":"TwitterAPI This class provides a Twitter API interface in order to interact with the Twitter Search API v2. It is built on top of the tweepy.Client class. Thus, it supports all methods from the Tweepy client. Additional functions are added. The following functions are available: user_info compare_users tweet_info compare_tweets Initialization Header: TwitterAPI(bearer_token: Optional[Any] = None, consumer_key: Optional[Any] = None, consumer_secret: Optional[Any] = None, access_token: Optional[Any] = None, access_token_secret: Optional[Any] = None, x_rapidapi_key: Optional[Any] = None, x_rapidapi_host: Optional[Any] = None, wait_on_rate_limit: bool = True) Args: bearer_token : Twitter API OAuth 2.0 Bearer Token consumer_key : Twitter API OAuth 1.0a Consumer Key consumer_secret : Twitter API OAuth 1.0a Consumer Secret access_token : Twitter API OAuth 1.0a Access Token access_token_secret : Twitter API OAuth 1.0a Access Token Secret x_rapidapi_key : Access Token for the Botometer API from the RapidAPI platform x_rapidapi_host : Host for the Botometer API from the RapidAPI platform wait_on_rate_limit : Whether to wait when rate limit is reached. Defaults to True. user_info Function: TwitterAPI.user_info(user: str | int, attributes: List[LITERALS_USER_INFO] | str, return_timestamp: bool = False) Receive requested user information from Twitter User Object. This function takes in a Twitter user identifier (i.e., an ID or unique screen name). The attributes are passed in by a list object or by a single string. For a single provided attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. If the requested attribute for the objet is not available, None will be returned. Args: user (str | int): Twitter User either specified by corresponding ID or screen name. attributes (List[LITERALS_USER_INFO] | str): Attributes of the User object. These must be from this list: Detailed description of user information attributes . See the link for detailed description of the attributes. return_timestamp (bool): Add UTC Timestamp of the request to results. Defaults to False. References: https://developer.twitter.com/en/docs/twitter-api/v1/accounts-and-users/follow-search-get-users/api-reference/get-users-lookup https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user Example: # request user information from the University of M\u00fcnster results = api.user_info(\"WWU_Muenster\", [\"id\", \"created_at\", \"last_active\", \"followers_count\"]) print(results) will print: {'id': 24677217, 'created_at': 'Mon Mar 16 11:19:30 +0000 2009', 'last_active': 'Wed Feb 15 13:51:04 +0000 2023', 'followers_count': 20183} compare_users Function: TwitterAPI.compare_users(users: List[str | int], compare: str | List[LITERALS_COMPARE_USERS], return_timestamp: bool = False, features: List[str] | None = None) Compare two or more users with the specified comparison attribute(s). This function takes in multiple Twitter user identifiers (i.e., IDs or unique screen names). The comparison attributes are passed in by a list object or by a single string. For a single attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Args: users (List[str | int]): User IDs or unique screen names. compare (str | List[LITERALS_COMPARE_USERS]): Comparison attribute(s) by which users are compared. These must be from this list: Detailed description of user comparison attributes . See the link for detailed description of the attributes. return_timestamp (bool, optional): Add UTC Timestamp of the request to results. Defaults to False. features (List[str], optional): Defined features of Twitter User Object on which similarity will be computed. Must be from: followers_count , friends_count , listed_count , favourites_count , statuses_count . Must be provided if similarity comparison attribute was passed in. Defaults to None. References: https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user https://developer.twitter.com/en/docs/twitter-api/v1/accounts-and-users/follow-search-get-users/api-reference/get-friendships-show Example: # compare number of tweets results = api.compare_users([\"WWU_Muenster\", \"goetheuni\", \"UniKonstanz\"], compare=\"tweets_count\", return_timestamp=True) print(results) will print: {'tweets_count': { 'WWU_Muenster': 11670, 'goetheuni': 7245, 'UniKonstanz': 9857, 'metrics': { 'max': 11670, 'min': 7245, 'mean': 9590.666666666666, 'median': 9857.0, 'std': 1816.288584510243, 'var': 3298904.222222222, 'range': 4425, 'IQR': 2212.5, 'mad': 1563.777777777778}}, 'utc_timestamp': '2023-02-12 18:05:33.152930'} tweet_info Function: tweet_info(tweet_id: str | int, attributes: List[LITERALS_TWEET_INFO] | str, return_timestamp: bool = False) Receive requested Tweet information from Tweet Object. This function takes in a tweet ID as string or integer representation. The attributes are passed in by a list object or by a single string. For a single provided attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. If the requested attribute for the objet is not available, None will be returned. Args: tweet_id (str | int): Tweet ID either in string or integer representation. attributes (List[LITERALS_TWEET_INFO] | str): Attribute(s) of the Tweet object. These must be from this list: Detailed description of Tweet information attributes . See the link for detailed description of the attributes. return_timestamp (bool, optional): Add UTC Timestamp of the request to results. Defaults to False. References: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/post-and-engage/api-reference/get-statuses-lookup https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet https://developer.twitter.com/en/docs/twitter-api/annotations/overview Example: # request creation date, language, and sentiment attributes for specified Tweet results = api.tweet_info(1612443577447026689, [\"created_at\", \"lang\", \"sentiment\"], return_timestamp=True) print(results) will print: { 'created_at': 'Mon Jan 09 13:38:01 +0000 2023', 'lang': 'de', 'sentiment': 'neutral', 'utc_timestamp': '2023-02-12 18:02:52.622169' } compare_tweets Function: compare_tweets(tweet_ids: List[str | int], compare: str | List[LITERALS_COMPARE_TWEETS], return_timestamp: bool = False, features: List[str] | None = None) Compare two or more Tweets with the specified comparison attribute. This function takes in multiple tweet IDs as string or integer representation. The comparison attributes are passed in by a list object or by a single string. For a single attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Args: tweet_ids (List[str | int]): Tweet IDs either in string or integer representation. At least two Tweet IDs are required. compare (str | List[LITERALS_COMPARE_TWEETS]): Comparison attribute(s) by which Tweets are compared. These must be from this list: Detailed description of Tweet comparison attributes . See the link for detailed description of the attributes. return_timestamp (bool optional): Add UTC Timestamp of the request to results. Defaults to False. features (List[str], optional): Defined features of Tweet Object on which similarity will be computed. Must be from: public_metrics (i.e., retweet_count , reply_count , like_count , quote_count , impression_count ). Must be provided if similarity comparison attribute was passed in. Defaults to None. References: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/post-and-engage/api-reference/get-statuses-lookup https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet Example: # get common liking users of specified Tweets results = api.compare_tweets(tweet_ids=[1612443577447026689, 1611301422364082180, 1612823288723476480], compare=\"common_liking_users\") print(results) will print: [3862364523] For all functions, a comparison over time can be achieved by using the return_timestamp argument for each request, storing the data in a JSON or CSV file using the export_to_json and export_to_csv , respectively, and append new records to existing files with the append_to_json or append_to_csv utility functions. Example: # request results for Tweet comparison, return timestamp results = api.compare_tweets([1612443577447026689, 1611301422364082180, 1612823288723476480], compare=[\"common_liking_users\"], return_timestamp=True) # export to JSON file export_to_json(results, export_path=\"compare_tweets.json\") # some time later... # generate new results that should be appended in the next step new_results = api.compare_tweets([1612443577447026689, 1611301422364082180, 1612823288723476480], compare=[\"common_liking_users\"], return_timestamp=True) # append to an existing file. append_to_json(new_results, \"compare_tweets.json\") The compare_tweets.json could then look like this: { \"data\": [ { \"common_liking_users\": [3862364523], \"utc_timestamp\": \"2023-02-21 11:26:45.885444\" }, { \"common_liking_users\": [3862364523, 20965264523], \"utc_timestamp\": \"2023-02-22 12:31:23.765328\" } ] }","title":"TwitterAPI"},{"location":"user-guide/overview/TwitterAPI/#twitterapi","text":"This class provides a Twitter API interface in order to interact with the Twitter Search API v2. It is built on top of the tweepy.Client class. Thus, it supports all methods from the Tweepy client. Additional functions are added. The following functions are available: user_info compare_users tweet_info compare_tweets","title":"TwitterAPI"},{"location":"user-guide/overview/TwitterAPI/#initialization","text":"Header: TwitterAPI(bearer_token: Optional[Any] = None, consumer_key: Optional[Any] = None, consumer_secret: Optional[Any] = None, access_token: Optional[Any] = None, access_token_secret: Optional[Any] = None, x_rapidapi_key: Optional[Any] = None, x_rapidapi_host: Optional[Any] = None, wait_on_rate_limit: bool = True) Args: bearer_token : Twitter API OAuth 2.0 Bearer Token consumer_key : Twitter API OAuth 1.0a Consumer Key consumer_secret : Twitter API OAuth 1.0a Consumer Secret access_token : Twitter API OAuth 1.0a Access Token access_token_secret : Twitter API OAuth 1.0a Access Token Secret x_rapidapi_key : Access Token for the Botometer API from the RapidAPI platform x_rapidapi_host : Host for the Botometer API from the RapidAPI platform wait_on_rate_limit : Whether to wait when rate limit is reached. Defaults to True.","title":"Initialization"},{"location":"user-guide/overview/TwitterAPI/#user_info","text":"Function: TwitterAPI.user_info(user: str | int, attributes: List[LITERALS_USER_INFO] | str, return_timestamp: bool = False) Receive requested user information from Twitter User Object. This function takes in a Twitter user identifier (i.e., an ID or unique screen name). The attributes are passed in by a list object or by a single string. For a single provided attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. If the requested attribute for the objet is not available, None will be returned. Args: user (str | int): Twitter User either specified by corresponding ID or screen name. attributes (List[LITERALS_USER_INFO] | str): Attributes of the User object. These must be from this list: Detailed description of user information attributes . See the link for detailed description of the attributes. return_timestamp (bool): Add UTC Timestamp of the request to results. Defaults to False. References: https://developer.twitter.com/en/docs/twitter-api/v1/accounts-and-users/follow-search-get-users/api-reference/get-users-lookup https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user Example: # request user information from the University of M\u00fcnster results = api.user_info(\"WWU_Muenster\", [\"id\", \"created_at\", \"last_active\", \"followers_count\"]) print(results) will print: {'id': 24677217, 'created_at': 'Mon Mar 16 11:19:30 +0000 2009', 'last_active': 'Wed Feb 15 13:51:04 +0000 2023', 'followers_count': 20183}","title":"user_info"},{"location":"user-guide/overview/TwitterAPI/#compare_users","text":"Function: TwitterAPI.compare_users(users: List[str | int], compare: str | List[LITERALS_COMPARE_USERS], return_timestamp: bool = False, features: List[str] | None = None) Compare two or more users with the specified comparison attribute(s). This function takes in multiple Twitter user identifiers (i.e., IDs or unique screen names). The comparison attributes are passed in by a list object or by a single string. For a single attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Args: users (List[str | int]): User IDs or unique screen names. compare (str | List[LITERALS_COMPARE_USERS]): Comparison attribute(s) by which users are compared. These must be from this list: Detailed description of user comparison attributes . See the link for detailed description of the attributes. return_timestamp (bool, optional): Add UTC Timestamp of the request to results. Defaults to False. features (List[str], optional): Defined features of Twitter User Object on which similarity will be computed. Must be from: followers_count , friends_count , listed_count , favourites_count , statuses_count . Must be provided if similarity comparison attribute was passed in. Defaults to None. References: https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user https://developer.twitter.com/en/docs/twitter-api/v1/accounts-and-users/follow-search-get-users/api-reference/get-friendships-show Example: # compare number of tweets results = api.compare_users([\"WWU_Muenster\", \"goetheuni\", \"UniKonstanz\"], compare=\"tweets_count\", return_timestamp=True) print(results) will print: {'tweets_count': { 'WWU_Muenster': 11670, 'goetheuni': 7245, 'UniKonstanz': 9857, 'metrics': { 'max': 11670, 'min': 7245, 'mean': 9590.666666666666, 'median': 9857.0, 'std': 1816.288584510243, 'var': 3298904.222222222, 'range': 4425, 'IQR': 2212.5, 'mad': 1563.777777777778}}, 'utc_timestamp': '2023-02-12 18:05:33.152930'}","title":"compare_users"},{"location":"user-guide/overview/TwitterAPI/#tweet_info","text":"Function: tweet_info(tweet_id: str | int, attributes: List[LITERALS_TWEET_INFO] | str, return_timestamp: bool = False) Receive requested Tweet information from Tweet Object. This function takes in a tweet ID as string or integer representation. The attributes are passed in by a list object or by a single string. For a single provided attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. If the requested attribute for the objet is not available, None will be returned. Args: tweet_id (str | int): Tweet ID either in string or integer representation. attributes (List[LITERALS_TWEET_INFO] | str): Attribute(s) of the Tweet object. These must be from this list: Detailed description of Tweet information attributes . See the link for detailed description of the attributes. return_timestamp (bool, optional): Add UTC Timestamp of the request to results. Defaults to False. References: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/post-and-engage/api-reference/get-statuses-lookup https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet https://developer.twitter.com/en/docs/twitter-api/annotations/overview Example: # request creation date, language, and sentiment attributes for specified Tweet results = api.tweet_info(1612443577447026689, [\"created_at\", \"lang\", \"sentiment\"], return_timestamp=True) print(results) will print: { 'created_at': 'Mon Jan 09 13:38:01 +0000 2023', 'lang': 'de', 'sentiment': 'neutral', 'utc_timestamp': '2023-02-12 18:02:52.622169' }","title":"tweet_info"},{"location":"user-guide/overview/TwitterAPI/#compare_tweets","text":"Function: compare_tweets(tweet_ids: List[str | int], compare: str | List[LITERALS_COMPARE_TWEETS], return_timestamp: bool = False, features: List[str] | None = None) Compare two or more Tweets with the specified comparison attribute. This function takes in multiple tweet IDs as string or integer representation. The comparison attributes are passed in by a list object or by a single string. For a single attribute, only the corresponding value is returned. For multiple attributes, a dictionary with the key-value pairs of the requested attributes is returned. Args: tweet_ids (List[str | int]): Tweet IDs either in string or integer representation. At least two Tweet IDs are required. compare (str | List[LITERALS_COMPARE_TWEETS]): Comparison attribute(s) by which Tweets are compared. These must be from this list: Detailed description of Tweet comparison attributes . See the link for detailed description of the attributes. return_timestamp (bool optional): Add UTC Timestamp of the request to results. Defaults to False. features (List[str], optional): Defined features of Tweet Object on which similarity will be computed. Must be from: public_metrics (i.e., retweet_count , reply_count , like_count , quote_count , impression_count ). Must be provided if similarity comparison attribute was passed in. Defaults to None. References: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/post-and-engage/api-reference/get-statuses-lookup https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet Example: # get common liking users of specified Tweets results = api.compare_tweets(tweet_ids=[1612443577447026689, 1611301422364082180, 1612823288723476480], compare=\"common_liking_users\") print(results) will print: [3862364523] For all functions, a comparison over time can be achieved by using the return_timestamp argument for each request, storing the data in a JSON or CSV file using the export_to_json and export_to_csv , respectively, and append new records to existing files with the append_to_json or append_to_csv utility functions. Example: # request results for Tweet comparison, return timestamp results = api.compare_tweets([1612443577447026689, 1611301422364082180, 1612823288723476480], compare=[\"common_liking_users\"], return_timestamp=True) # export to JSON file export_to_json(results, export_path=\"compare_tweets.json\") # some time later... # generate new results that should be appended in the next step new_results = api.compare_tweets([1612443577447026689, 1611301422364082180, 1612823288723476480], compare=[\"common_liking_users\"], return_timestamp=True) # append to an existing file. append_to_json(new_results, \"compare_tweets.json\") The compare_tweets.json could then look like this: { \"data\": [ { \"common_liking_users\": [3862364523], \"utc_timestamp\": \"2023-02-21 11:26:45.885444\" }, { \"common_liking_users\": [3862364523, 20965264523], \"utc_timestamp\": \"2023-02-22 12:31:23.765328\" } ] }","title":"compare_tweets"},{"location":"user-guide/overview/Utilities/","text":"Utility Functions Utility functions are defined to read and write to specific files. The files can be imported via from pysna.utils import export_to_json, export_to_csv, append_to_json, append_to_csv, load_from_json or are included in the import-all-statement: from pysna import * Export to JSON Function: export_to_json(data: dict, export_path: str, encoding: str = 'utf-8', ensure_ascii: bool = False, *args) Export dictionary data to JSON file. Function will add a data key for the JSON file and store the provided dictionary inside the data field. Args: data (dict): Data dictionary. export_path (str): Export path including file name and extension. encoding (str, optional): Encoding of JSON file. Defaults to UTF-8. args (optional): Further arguments to be passed to json.dump() . References: https://docs.python.org/3/library/json.html NOTE: When trying to export a dictionary containing tuples as keys, the function will try to serialize them by converting tuples to strings. Then, a tuple like (\"WWU_Muenster\", \"goetheuni\") will be encoded to: \"__tuples__['WWU_Muenster', 'goetheuni']\" . For recovering the original dictionary after JSON export, use the load_from_json function. Example: # request results for Tweet comparison, return timestamp results = api.compare_tweets([1612443577447026689, 1611301422364082180, 1612823288723476480], compare=[\"common_liking_users\"], return_timestamp=True) # export to JSON file export_to_json(results, export_path=\"compare_tweets.json\") The exported compare_tweets.json file will the look like: { \"data\": [ { \"common_liking_users\": [ 3862364523 ], \"utc_timestamp\": \"2023-01-31 09:22:11.996652\" } } Append to JSON Function: append_to_json(input_dict: Dict[str, Any], filepath: str, encoding: str = \"utf-8\", **kwargs) Append a dictionary to an existing JSON file. Existing JSON file needs a 'data' key. Args: input_dict : Dictionary containing new data that should be added to file. filepath : Absolute or relative filepath including the file extension. Depending on the current working directory. encoding : The encoding of the file. Defaults to UTF-8. kwargs : Additional keyword arguments to be passed to json.dump() and json.load() References: https://docs.python.org/3/library/json.html Note: When trying to append a dictionary containing tuples as keys, the function will try to serialize them by converting tuples to strings. For recovering the original dictionary after JSON export, use the load_from_json function. Example: # generate new results that should be appended in the next step new_results = api.compare_tweets([1612443577447026689, 1611301422364082180, 1612823288723476480], compare=[\"common_liking_users\"], return_timestamp=True) # append to an existing file. append_to_json(new_results, \"compare_tweets.json\") The extended compare_tweets.json file will be supplemented with one further entry within the data field. An example output could look like: { \"data\": [ { \"common_liking_users\": [ 3862364523 ], \"utc_timestamp\": \"2023-01-31 09:22:11.996652\" }, { \"common_liking_users\": [ 3862364523 ], \"utc_timestamp\": \"2023-01-31 09:23:05.848485\" } ] } Load from JSON Function: load_from_json(filepath: str, encoding: str = \"utf-8\", **kwargs) -> dict Load Python Dictionary from JSON file. Tuples are recovered. Args: filepath (str): Path to JSON file. encoding (str, optional): Encoding of file. Defaults to UTF-8. kwargs (optional): Keyword arguments to be passed to json.load() . Returns: Python Dictionary containing (deserialized) data from JSON file. References: https://docs.python.org/3/library/json.html NOTE : Tuples that have been encoded by the export_to_json function with a leading __tuples__ string will be recovered to original tuple representation. For instance, a encoded tuple __tuple__ [\"WWU_Muenster\", \"goetheuni\"] will be returned as (\"WWU_Muenster\", \"goetheuni\") . Example: Suppose an example.json file containing one entry with a serialized tuple key: { \"data\": [ { \"__tuple__ ['WWU_Muenster', 'goetheuni']\": 0.578077 } ] } By calling: from pysna.utils import load_from_json data = load_from_json(\"example.json\") print(data) the tuple will be recovered and a conventional Python Dictionary will be returned: {(\"WWU_Muenster\", \"goetheuni\"): 0.578077} Export to CSV Function: export_to_csv(data: dict, export_path: str, encoding: str = \"utf-8\", sep: str = \",\", **kwargs) Export dictionary data to CSV file. Will raise an exception if data dictionary contains nested dictionaries. Args: data (dict): Data dictionary export_path (str): Exportpath including file name and extension. encoding (str, optional): Encoding of CSV file. Defaults to UTF-8. sep (str, optional): Value separator for CSV file. Defaults to ',' . kwargs (optional): Keyword arguments for pandas.DataFrame.to_csv . References: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html Example: # request results for user information, return timestamp results = api.user_info(\"WWU_Muenster\", [\"id\", \"location\", \"friends_count\", \"followers_count\", \"last_active\", \"statuses_count\"], return_timestamp=True) # export to CSV file export_to_csv(results, export_path=\"user_info.csv\") Append to CSV Function: append_to_csv(data: dict, filepath: str, encoding: str = \"utf-8\", sep: str = \",\", *args) Append a dictionary to an existing CSV file. Will raise an exception if data dictionary contains nested dictionaries. Args: data (dict): Dictionary containing new data that should be added to file. filepath (str): Absolute or relative filepath including the file extension. Depending on the current working directory. encoding (str, optional): Encoding of CSV file. Defaults to UTF-8. sep (str, optional): Value separator for CSV file. Defaults to \",\". args : Keyword Arguments for reading and writing from/to CSV file from pandas. Pass in: *[read_kwargs, write_kwargs] , whereas both are dictionaries (i.e., provide a list of two dictionaries). References: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html Example: # request results for user information, return timestamp results = api.user_info(\"WWU_Muenster\", [\"id\", \"location\", \"friends_count\", \"followers_count\", \"last_active\", \"statuses_count\"], return_timestamp=True) # export to CSV file append_to_csv(results, filepath=\"user_info.csv\") Notes Only JSON and CSV file formats are supported, yet.","title":"Utility Functions"},{"location":"user-guide/overview/Utilities/#utility-functions","text":"Utility functions are defined to read and write to specific files. The files can be imported via from pysna.utils import export_to_json, export_to_csv, append_to_json, append_to_csv, load_from_json or are included in the import-all-statement: from pysna import *","title":"Utility Functions"},{"location":"user-guide/overview/Utilities/#export-to-json","text":"Function: export_to_json(data: dict, export_path: str, encoding: str = 'utf-8', ensure_ascii: bool = False, *args) Export dictionary data to JSON file. Function will add a data key for the JSON file and store the provided dictionary inside the data field. Args: data (dict): Data dictionary. export_path (str): Export path including file name and extension. encoding (str, optional): Encoding of JSON file. Defaults to UTF-8. args (optional): Further arguments to be passed to json.dump() . References: https://docs.python.org/3/library/json.html NOTE: When trying to export a dictionary containing tuples as keys, the function will try to serialize them by converting tuples to strings. Then, a tuple like (\"WWU_Muenster\", \"goetheuni\") will be encoded to: \"__tuples__['WWU_Muenster', 'goetheuni']\" . For recovering the original dictionary after JSON export, use the load_from_json function. Example: # request results for Tweet comparison, return timestamp results = api.compare_tweets([1612443577447026689, 1611301422364082180, 1612823288723476480], compare=[\"common_liking_users\"], return_timestamp=True) # export to JSON file export_to_json(results, export_path=\"compare_tweets.json\") The exported compare_tweets.json file will the look like: { \"data\": [ { \"common_liking_users\": [ 3862364523 ], \"utc_timestamp\": \"2023-01-31 09:22:11.996652\" } }","title":"Export to JSON"},{"location":"user-guide/overview/Utilities/#append-to-json","text":"Function: append_to_json(input_dict: Dict[str, Any], filepath: str, encoding: str = \"utf-8\", **kwargs) Append a dictionary to an existing JSON file. Existing JSON file needs a 'data' key. Args: input_dict : Dictionary containing new data that should be added to file. filepath : Absolute or relative filepath including the file extension. Depending on the current working directory. encoding : The encoding of the file. Defaults to UTF-8. kwargs : Additional keyword arguments to be passed to json.dump() and json.load() References: https://docs.python.org/3/library/json.html Note: When trying to append a dictionary containing tuples as keys, the function will try to serialize them by converting tuples to strings. For recovering the original dictionary after JSON export, use the load_from_json function. Example: # generate new results that should be appended in the next step new_results = api.compare_tweets([1612443577447026689, 1611301422364082180, 1612823288723476480], compare=[\"common_liking_users\"], return_timestamp=True) # append to an existing file. append_to_json(new_results, \"compare_tweets.json\") The extended compare_tweets.json file will be supplemented with one further entry within the data field. An example output could look like: { \"data\": [ { \"common_liking_users\": [ 3862364523 ], \"utc_timestamp\": \"2023-01-31 09:22:11.996652\" }, { \"common_liking_users\": [ 3862364523 ], \"utc_timestamp\": \"2023-01-31 09:23:05.848485\" } ] }","title":"Append to JSON"},{"location":"user-guide/overview/Utilities/#load-from-json","text":"Function: load_from_json(filepath: str, encoding: str = \"utf-8\", **kwargs) -> dict Load Python Dictionary from JSON file. Tuples are recovered. Args: filepath (str): Path to JSON file. encoding (str, optional): Encoding of file. Defaults to UTF-8. kwargs (optional): Keyword arguments to be passed to json.load() . Returns: Python Dictionary containing (deserialized) data from JSON file. References: https://docs.python.org/3/library/json.html NOTE : Tuples that have been encoded by the export_to_json function with a leading __tuples__ string will be recovered to original tuple representation. For instance, a encoded tuple __tuple__ [\"WWU_Muenster\", \"goetheuni\"] will be returned as (\"WWU_Muenster\", \"goetheuni\") . Example: Suppose an example.json file containing one entry with a serialized tuple key: { \"data\": [ { \"__tuple__ ['WWU_Muenster', 'goetheuni']\": 0.578077 } ] } By calling: from pysna.utils import load_from_json data = load_from_json(\"example.json\") print(data) the tuple will be recovered and a conventional Python Dictionary will be returned: {(\"WWU_Muenster\", \"goetheuni\"): 0.578077}","title":"Load from JSON"},{"location":"user-guide/overview/Utilities/#export-to-csv","text":"Function: export_to_csv(data: dict, export_path: str, encoding: str = \"utf-8\", sep: str = \",\", **kwargs) Export dictionary data to CSV file. Will raise an exception if data dictionary contains nested dictionaries. Args: data (dict): Data dictionary export_path (str): Exportpath including file name and extension. encoding (str, optional): Encoding of CSV file. Defaults to UTF-8. sep (str, optional): Value separator for CSV file. Defaults to ',' . kwargs (optional): Keyword arguments for pandas.DataFrame.to_csv . References: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html Example: # request results for user information, return timestamp results = api.user_info(\"WWU_Muenster\", [\"id\", \"location\", \"friends_count\", \"followers_count\", \"last_active\", \"statuses_count\"], return_timestamp=True) # export to CSV file export_to_csv(results, export_path=\"user_info.csv\")","title":"Export to CSV"},{"location":"user-guide/overview/Utilities/#append-to-csv","text":"Function: append_to_csv(data: dict, filepath: str, encoding: str = \"utf-8\", sep: str = \",\", *args) Append a dictionary to an existing CSV file. Will raise an exception if data dictionary contains nested dictionaries. Args: data (dict): Dictionary containing new data that should be added to file. filepath (str): Absolute or relative filepath including the file extension. Depending on the current working directory. encoding (str, optional): Encoding of CSV file. Defaults to UTF-8. sep (str, optional): Value separator for CSV file. Defaults to \",\". args : Keyword Arguments for reading and writing from/to CSV file from pandas. Pass in: *[read_kwargs, write_kwargs] , whereas both are dictionaries (i.e., provide a list of two dictionaries). References: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html Example: # request results for user information, return timestamp results = api.user_info(\"WWU_Muenster\", [\"id\", \"location\", \"friends_count\", \"followers_count\", \"last_active\", \"statuses_count\"], return_timestamp=True) # export to CSV file append_to_csv(results, filepath=\"user_info.csv\")","title":"Append to CSV"},{"location":"user-guide/overview/Utilities/#notes","text":"Only JSON and CSV file formats are supported, yet.","title":"Notes"},{"location":"user-guide/overview/cli/","text":"Command-line Interface Tool The main functions from the TwitterAPI class are also available on the CLI. To see the usage instructions and help, run: pysna -h If you wish to see the usage instructions for a function, run: pysna <function> --help For example, if you want to request a comparison of two users, you can run: pysna compare-users \"WWU_Muenster\" \"goetheuni\" -c \"tweets_count\" \"common_followers\" -o \"results.json\" --return-timestamp This will perform a comparison on the \"WWU_Muenster\" and \"goetheuni\" Twitter Accounts based their number of composed Tweets and their common followers. The results are exported to the results.json file. Also, the timestamp of the request will be returned. NOTE : Every request needs valid credentials for the official Twitter API. Thus, pass in a .env file to every function call by using the --env flag or use the set-secrets function to set the API secrets for upcoming requests (recommended). Functions set-secrets In order to set the API secrets to run every command from any working directory, it is recommended to use this function. The function will copy the given .env file to the ~/.pysna/config/ directory and will create a config file containing your API secrets. This file will be read every time a request is made. If you wish to overwrite the existing config file containing the secrets, rerun this function with a new .env file. If you wish to use other secrets for authentification sporadically, you can use the --env flag of every function to use different secrets than specified in the config file. NOTE : The provided .env file must have the format: BEARER_TOKEN=... CONSUMER_KEY=... CONSUMER_SECRET=... ACCESS_TOKEN=... ACCESS_TOKEN_SECRET=... X_RAPIDAPI_KEY=... X_RAPIDAPI_HOST=... BEARER_TOKEN : Twitter API OAuth 2.0 Bearer Token CONSUMER_KEY : Twitter API OAuth 1.0a Consumer Key CONSUMER_SECRET : Twitter API OAuth 1.0a Consumer Secret ACCESS_TOKEN : Twitter API OAuth 1.0a Access Token ACCESS_TOKEN_SECRET : Twitter API OAuth 1.0a Access Token Secret X_RAPIDAPI_KEY : Access Token for the Botometer API from the RapidAPI platform X_RAPIDAPI_HOST : Host for the Botometer API from the RapidAPI platform Only .env files are supported, yet. Example: pysna set-secrets local.env or, if you want to use different secrets for a request, use the --env flag: pysna compare-users [...] --env ./local.env user-info Command: pysna user-info <user> <attributes> [--return-timestamp] [--output] [--append] [--encoding] [--env] Args: user (required): Twitter User ID or unique screen name attributes (required): pass in desired attributes separated by space. For a list of attributes, see here . return-timestamp (optional): return UTC timestamp of the query. output (optional): writes the output to a file. Pass in the file path and file name including the extension. If empty, output is printed to the CLI. Currently, CSV and JSON exports are supported. (e.g., write output.json for JSON export.). Flag short form: -o . append (optional): appends the output to an existing file. Pass in the path to the existing file with the output flag. encoding (optional): specify file encoding. Defaults to UTF-8. env (positional): specify path to environment file. Defaults to ~/.pysna/config/secrets.env (i.e., the config file path set via the set-secrets function). Flag short form: -e . compare-users Command: pysna compare-users <users> -c <compare> [--features] [--return-timestamp] [--output] [--append] [--encoding] [--env] Args: users (required): IDs or unique screen names of Twitter users. Pass in the users separated by space. compare (required): Comparison attributes Must be from the following: relationship , followers_count , followees_count , tweets_count , favourites_count , common_followers , distinct_followers , common_followees , distinct_followees , commonly_liked_tweets , distinctly_liked_tweets , similarity , created_at , protected , verified . For an overview of what the comparison attributes do, see here . Provide the comparison attributes separated by space after the -c flag. features (positional): Define the components of the feature vector for the similarity comparison attribute. Must be passed in if the aforementioned comparison attribute was provided. Features must be from: followers_count , friends_count , listed_count , favourites_count , statuses_count . return-timestamp (optional): return UTC timestamp of the query. output (optional): writes the output to a file. Pass in the file path and file name including the extension. If empty, output is printed to the CLI. Currently, CSV and JSON exports are supported. (e.g., write output.json for JSON export.). Flag short form: -o . append (optional): appends the output to an existing file. Pass in the path to the existing file with the output flag. encoding (optional): specify file encoding. Defaults to UTF-8. env (positional): specify path to environment file. Defaults to ~/.pysna/config/secrets.env (i.e., the config file path set via the set-secrets function). Flag short form: -e . tweet-info Command: pysna tweet-info <tweet> <attributes> [--return-timestamp] [--output] [--append] [--encoding] [--env] Args: tweet (required): Unique Tweet ID. attributes (required): pass in desired attributes separated by space. For a list of attributes, see here . return-timestamp (optional): return UTC timestamp of the query. output (optional): writes the output to a file. Pass in the file path and file name including the extension. If empty, output is printed to the CLI. Currently, CSV and JSON exports are supported. (e.g., write output.json for JSON export.) Flag short form: -o . append (optional): appends the output to an existing file. Pass in the path to the existing file with the output flag. encoding (optional): specify file encoding. Defaults to UTF-8. env (positional): specify path to environment file. Defaults to ~/.pysna/config/secrets.env (i.e., the config file path set via the set-secrets function). Flag short form: -e . compare-tweets Command: pysna compare-tweets <tweets> -c <compare> [--features] [--return-timestamp] [--output] [--append] [--encoding] [--env] Args: tweets (required): Unique Tweet IDs separated by space. compare (required): Comparison attributes Must be from the following: view_count , like_count , retweet_count , quote_count , reply_count , common_quoting_users , distinct_quoting_users , common_liking_users , distinct_liking_users , common_retweeters , distinct_retweeters , similarity , created_at . For an overview of what the comparison attributes do, see here . Provide the comparison attributes separated by space after the -c flag. features (positional): Define the components of the feature vector for the similarity comparison attribute. Must be passed in if the aforementioned comparison attribute was provided. Features must be from: retweet_count , favorite_count . return-timestamp (optional): return UTC timestamp of the query. output (optional): writes the output to a file. Pass in the file path and file name including the extension. If empty, output is printed to the CLI. Currently, CSV and JSON exports are supported. (e.g., write output.json for JSON export.). Flag short form: -o . append (optional): appends the output to an existing file. Pass in the path to the existing file with the output flag. encoding (optional): specify file encoding. Defaults to UTF-8. env (positional): specify path to environment file. Defaults to ~/.pysna/config/secrets.env (i.e., the config file path set via the set-secrets function). Flag short form: -e .","title":"CLI Tool"},{"location":"user-guide/overview/cli/#command-line-interface-tool","text":"The main functions from the TwitterAPI class are also available on the CLI. To see the usage instructions and help, run: pysna -h If you wish to see the usage instructions for a function, run: pysna <function> --help For example, if you want to request a comparison of two users, you can run: pysna compare-users \"WWU_Muenster\" \"goetheuni\" -c \"tweets_count\" \"common_followers\" -o \"results.json\" --return-timestamp This will perform a comparison on the \"WWU_Muenster\" and \"goetheuni\" Twitter Accounts based their number of composed Tweets and their common followers. The results are exported to the results.json file. Also, the timestamp of the request will be returned. NOTE : Every request needs valid credentials for the official Twitter API. Thus, pass in a .env file to every function call by using the --env flag or use the set-secrets function to set the API secrets for upcoming requests (recommended).","title":"Command-line Interface Tool"},{"location":"user-guide/overview/cli/#functions","text":"","title":"Functions"},{"location":"user-guide/overview/cli/#set-secrets","text":"In order to set the API secrets to run every command from any working directory, it is recommended to use this function. The function will copy the given .env file to the ~/.pysna/config/ directory and will create a config file containing your API secrets. This file will be read every time a request is made. If you wish to overwrite the existing config file containing the secrets, rerun this function with a new .env file. If you wish to use other secrets for authentification sporadically, you can use the --env flag of every function to use different secrets than specified in the config file. NOTE : The provided .env file must have the format: BEARER_TOKEN=... CONSUMER_KEY=... CONSUMER_SECRET=... ACCESS_TOKEN=... ACCESS_TOKEN_SECRET=... X_RAPIDAPI_KEY=... X_RAPIDAPI_HOST=... BEARER_TOKEN : Twitter API OAuth 2.0 Bearer Token CONSUMER_KEY : Twitter API OAuth 1.0a Consumer Key CONSUMER_SECRET : Twitter API OAuth 1.0a Consumer Secret ACCESS_TOKEN : Twitter API OAuth 1.0a Access Token ACCESS_TOKEN_SECRET : Twitter API OAuth 1.0a Access Token Secret X_RAPIDAPI_KEY : Access Token for the Botometer API from the RapidAPI platform X_RAPIDAPI_HOST : Host for the Botometer API from the RapidAPI platform Only .env files are supported, yet. Example: pysna set-secrets local.env or, if you want to use different secrets for a request, use the --env flag: pysna compare-users [...] --env ./local.env","title":"set-secrets"},{"location":"user-guide/overview/cli/#user-info","text":"Command: pysna user-info <user> <attributes> [--return-timestamp] [--output] [--append] [--encoding] [--env] Args: user (required): Twitter User ID or unique screen name attributes (required): pass in desired attributes separated by space. For a list of attributes, see here . return-timestamp (optional): return UTC timestamp of the query. output (optional): writes the output to a file. Pass in the file path and file name including the extension. If empty, output is printed to the CLI. Currently, CSV and JSON exports are supported. (e.g., write output.json for JSON export.). Flag short form: -o . append (optional): appends the output to an existing file. Pass in the path to the existing file with the output flag. encoding (optional): specify file encoding. Defaults to UTF-8. env (positional): specify path to environment file. Defaults to ~/.pysna/config/secrets.env (i.e., the config file path set via the set-secrets function). Flag short form: -e .","title":"user-info"},{"location":"user-guide/overview/cli/#compare-users","text":"Command: pysna compare-users <users> -c <compare> [--features] [--return-timestamp] [--output] [--append] [--encoding] [--env] Args: users (required): IDs or unique screen names of Twitter users. Pass in the users separated by space. compare (required): Comparison attributes Must be from the following: relationship , followers_count , followees_count , tweets_count , favourites_count , common_followers , distinct_followers , common_followees , distinct_followees , commonly_liked_tweets , distinctly_liked_tweets , similarity , created_at , protected , verified . For an overview of what the comparison attributes do, see here . Provide the comparison attributes separated by space after the -c flag. features (positional): Define the components of the feature vector for the similarity comparison attribute. Must be passed in if the aforementioned comparison attribute was provided. Features must be from: followers_count , friends_count , listed_count , favourites_count , statuses_count . return-timestamp (optional): return UTC timestamp of the query. output (optional): writes the output to a file. Pass in the file path and file name including the extension. If empty, output is printed to the CLI. Currently, CSV and JSON exports are supported. (e.g., write output.json for JSON export.). Flag short form: -o . append (optional): appends the output to an existing file. Pass in the path to the existing file with the output flag. encoding (optional): specify file encoding. Defaults to UTF-8. env (positional): specify path to environment file. Defaults to ~/.pysna/config/secrets.env (i.e., the config file path set via the set-secrets function). Flag short form: -e .","title":"compare-users"},{"location":"user-guide/overview/cli/#tweet-info","text":"Command: pysna tweet-info <tweet> <attributes> [--return-timestamp] [--output] [--append] [--encoding] [--env] Args: tweet (required): Unique Tweet ID. attributes (required): pass in desired attributes separated by space. For a list of attributes, see here . return-timestamp (optional): return UTC timestamp of the query. output (optional): writes the output to a file. Pass in the file path and file name including the extension. If empty, output is printed to the CLI. Currently, CSV and JSON exports are supported. (e.g., write output.json for JSON export.) Flag short form: -o . append (optional): appends the output to an existing file. Pass in the path to the existing file with the output flag. encoding (optional): specify file encoding. Defaults to UTF-8. env (positional): specify path to environment file. Defaults to ~/.pysna/config/secrets.env (i.e., the config file path set via the set-secrets function). Flag short form: -e .","title":"tweet-info"},{"location":"user-guide/overview/cli/#compare-tweets","text":"Command: pysna compare-tweets <tweets> -c <compare> [--features] [--return-timestamp] [--output] [--append] [--encoding] [--env] Args: tweets (required): Unique Tweet IDs separated by space. compare (required): Comparison attributes Must be from the following: view_count , like_count , retweet_count , quote_count , reply_count , common_quoting_users , distinct_quoting_users , common_liking_users , distinct_liking_users , common_retweeters , distinct_retweeters , similarity , created_at . For an overview of what the comparison attributes do, see here . Provide the comparison attributes separated by space after the -c flag. features (positional): Define the components of the feature vector for the similarity comparison attribute. Must be passed in if the aforementioned comparison attribute was provided. Features must be from: retweet_count , favorite_count . return-timestamp (optional): return UTC timestamp of the query. output (optional): writes the output to a file. Pass in the file path and file name including the extension. If empty, output is printed to the CLI. Currently, CSV and JSON exports are supported. (e.g., write output.json for JSON export.). Flag short form: -o . append (optional): appends the output to an existing file. Pass in the path to the existing file with the output flag. encoding (optional): specify file encoding. Defaults to UTF-8. env (positional): specify path to environment file. Defaults to ~/.pysna/config/secrets.env (i.e., the config file path set via the set-secrets function). Flag short form: -e .","title":"compare-tweets"},{"location":"user-guide/overview/literals-compare-tweets/","text":"Detailed Description of the Attributes for the compare_tweets function: view_count : Compares the number of views the specified Tweets currently have. Will return additional statistical metrics on the numbers of views. like_count : Compares the number of likes the specified Tweets currently have. Will return additional statistical metrics on the numbers of likes. retweet_count : Compares the number of Retweets the specified Tweets currently have. Will return additional statistical metrics on the numbers of Retweets. quote_count : Compares the number of quotes the specified Tweets currently have. Will return additional statistical metrics on the numbers of quotes. reply_count : Compares the number of replies the specified Tweets currently have. Will return additional statistical metrics on the numbers of replies. common_quoting_users : Returns the set of quoting Twitter users all specified Tweets have in common. distinct_quoting_users : Returns the sets of distinct quoting Twitter users all specified Tweets have (i.e., the difference between the quoting Twitter users of all Tweets is calculated). common_liking_users : Returns the set of liking Twitter users all specified Tweets have in common. distinct_liking_users : Returns the sets of distinct liking Twitter users all specified Tweets have (i.e., the difference between the liking Twitter users of all Tweets is calculated). common_retweeters : Returns the set of retweeters all specified Tweets have in common. distinct_retweeters : Returns the sets of distinct retweeters all specified Tweets have (i.e., the difference between the retweeters of all Tweets is calculated). similarity : Computes the euclidean distance between two feature vectors. Each feature vector contains numerical attributes from each Tweet. The features that should be contained in the feature vector have to be provided in the features argument of the function. Available features are: retweet_count : The number of times a tweet was retweeted. reply_count : Number of replies a Tweet has. like_count : Number of likes a Tweet has. quote_count : Number of quotes a Tweet has. impression_count : Number of views a Tweet has. If more than two Tweets were provided, all possible pairs of combinations will be returned containing a distance. The smaller the distance, the more similar the Tweets are. Output will be sorted in ascending order, thus, most similar Tweets are on top. Each entry in the output contains a pair of two Tweets. created_at : Compares the specified Tweets on their creation dates. Additional Will return additional statistical metrics on the dates.","title":"Literals compare tweets"},{"location":"user-guide/overview/literals-compare-users/","text":"Detailed Description of the Attributes for the compare_users function: relationship : Returns detailed information about the relationship between a pair two arbitrary users. If more than two users were provided, all possible pairs of relationships will be returned. followers_count : Compares the number of followers the specified accounts currently have. Will return additional statistical metrics on the numbers of followers. followees_count : Compares the number of friends (AKA their \u201cfollowings\u201d or \"followees\") the specified accounts currently have. Will return additional statistical metrics on the numbers of friends. tweets_count : Compares the number of composed tweets the specified accounts currently have. Will return additional statistical metrics on the numbers of tweets. favourites_count : Compares the number of liked tweets the specified accounts currently have. Will return additional statistical metrics on the numbers of liked tweets. British spelling used in the field name for historical reasons. common_followers : Returns the set of followers all specified accounts have in common. distinct_followers : Returns the sets of distinct followers all specified accounts have (i.e., the difference between the followers of all accounts is calculated). common_followees : Returns the set of friends (AKA their \u201cfollowings\u201d or \"followees\") all specified accounts have in common. distinct_followees : Returns the sets of distinct friends (AKA their \u201cfollowings\u201d or \"followees\") all specified accounts have (i.e., the difference between the friends of all accounts is calculated). commonly_liked_tweets : Returns the set of liked tweets all specified accounts have in common. distinctly_liked_tweets : Returns the sets of distinct liked tweets all specified accounts have (i.e., the difference between all liked tweets of all accounts is calculated). similarity : Computes the euclidean distance between two feature vectors. Each feature vector contains numerical attributes from each user. The features that should be contained in the feature vector have to be provided in the features argument of the function. Available features are: followers_count : The number of followers this account currently has. friends_count : The number of users this account is following (AKA their \u201cfollowings\u201d or \"followees\"). listed_count : The number of public lists that this user is a member of. favourites_count : The number of Tweets this user has liked in the account\u2019s lifetime. British spelling used in the field name for historical reasons. statuses_count : The number of Tweets (including retweets) issued by the user. If more than two users were provided, all possible pairs of combinations will be returned containing a distance. The smaller the distance, the more similar the users are. Output will be sorted in ascending order, thus, most similar users are on top. Each entry in the output contains a pair of two users. created_at : Compares the specified accounts on their creation dates. Additional Will return additional statistical metrics on the dates. protected : Compares users on their protected attribute. When true, indicates that this user has chosen to protect their Tweets. verified : Compares users on their verified attribute. When true, indicates that the user has a verified account.","title":"Literals compare users"},{"location":"user-guide/overview/literals-tweet-info/","text":"Detailed Description of the Attributes for the tweet_info function: id : The integer representation of the unique identifier for this Tweet. id_str : The string representation of the unique identifier for this Tweet. full_text : The actual UTF-8 full text of the status update. If the tweet is a retweet (marked by a leading 'RT' within the text), the text will be truncated to 140 characters. The full text of the original tweet is contained within the display_text_range : The range of the tweet text characters provided as array containing the indexes of first and last character. retweeted_status field. Hence, add the retweeted_status fields to the attributes list and see under retweeted_status -> full_text fields for the full text of the retweet. truncated : Indicates whether the value of the text parameter was truncated, for example, as a result of a retweet exceeding the original Tweet text length limit of 140 characters. Truncated text will end in ellipsis, like this ... Since Twitter now rejects long Tweets vs truncating them, the large majority of Tweets will have this set to false . Note that while native retweets may have their toplevel text property shortened, the original text will be available under the retweeted_status object and the truncated parameter will be set to the value of the original status (in most cases, false ). created_at : UTC time when this Tweet was created. entities : Entities which have been parsed out of the text of the Tweet (hashtags, URLs, user mentions, media, symbols, polls). tweet_annotations : Context annotations and named entities of the Tweet object. Context annotations are derived from the analysis of a Tweet\u2019s text and will include a domain and entity pairing which can be used to discover Tweets on topics that may have been previously difficult to surface. Named Entities are comprised of people, places, products, and organizations. Entities are delivered as part of the entity payload section. They are programmatically assigned based on what is explicitly mentioned (named-entity recognition) in the Tweet text. See the official website for further details. source : Utility used to post the Tweet, as an HTML-formatted string. Tweets from the Twitter website have a source value of web . retweeters : Twitter user IDs from retweeters. in_reply_to_status_id : If the represented Tweet is a reply, this field will contain the integer representation of the original Tweet\u2019s ID. (Nullable) in_reply_to_status_id_str : If the represented Tweet is a reply, this field will contain the string representation of the original Tweet\u2019s ID. (Nullable) in_reply_to_user_id : If the represented Tweet is a reply, this field will contain the integer representation of the original Tweet\u2019s author ID. This will not necessarily always be the user directly mentioned in the Tweet. (Nullable) in_reply_to_user_id_str : If the represented Tweet is a reply, this field will contain the string representation of the original Tweet\u2019s author ID. This will not necessarily always be the user directly mentioned in the Tweet. (Nullable) in_reply_to_screen_name : If the represented Tweet is a reply, this field will contain the screen name of the original Tweet\u2019s author. (Nullable) user : The user who posted this Tweet. See User data dictionary for complete list of attributes. contributors : The contributors of the Tweet. coordinates : Represents the geographic location of this Tweet as reported by the user or client application. The inner coordinates array is formatted as geoJSON (longitude first, then latitude). (Nullable) place : When present, indicates that the tweet is associated (but not necessarily originating from) a place. (Nullable) is_quote_status : Indicates whether this is a Quoted Tweet. public_metrics : Public metrics for this Tweet containing (impressions_count (=views), quote_count, reply_count, retweet_count, favorite_count (=likes)) quoting_users : Twitter User IDs from users who quoted this Tweet. liking_users : Twitter User IDs from users who liked this Tweet. favorited : Indicates whether this Tweet has been liked by the authenticating user. (Nullable) retweeted : Indicates whether this Tweet has been Retweeted by the authenticating user. retweeted_status : Users can amplify the broadcast of Tweets authored by other users by retweeting . Retweets can be distinguished from typical Tweets by the existence of a retweeted_status attribute. This attribute contains a representation of the original Tweet that was retweeted. Note that retweets of retweets do not show representations of the intermediary retweet, but only the original Tweet. possibly_sensitive : This field indicates content may be recognized as sensitive. The Tweet author can select within their own account preferences and choose \u201cMark media you tweet as having material that may be sensitive\u201d so each Tweet created after has this flag set. This may also be judged and labeled by an internal Twitter support agent. (Nullable) lang : When present, indicates a BCP 47 language identifier corresponding to the machine-detected language of the Tweet text, or und if no language could be detected. See more documentation HERE . sentiment : The sentiment of the Tweet, either positive, neutral, or negative. Polarity scores are returned additionally. The sentiment is detected by using VADER . It is recommended to analyze only english Tweets. In case a Tweet of a different language is analyzed, results will still be returned but might not be accurate.","title":"Literals tweet info"},{"location":"user-guide/overview/literals-user-info/","text":"Detailed Description of the Attributes for the user_info function: id : The integer representation of the unique identifier for this User. id_str : The string representation of the unique identifier for this User. name : The name of the user, as they\u2019ve defined it. screen_name : The screen name, handle, or alias that this user identifies themselves with. followers : IDs, names, and screen names of the user's followers. followees : IDs, names, and screen names of the user's followees. location : The user-defined location for this account\u2019s profile. (Nullable) description : The user-defined UTF-8 string describing their account. (Nullable) url : A URL provided by the user in association with their profile. (Nullable) entities : Entities of the user object. protected : When true, indicates that this user has chosen to protect their Tweets. followers_count : The number of followers this account currently has. friends_count : The number of users this account is following (AKA their \u201cfollowings\u201d or \"followees\"). listed_count : The number of public lists that this user is a member of. created_at : The UTC datetime that the user account was created on Twitter. latest_activity : Latest acitivity according to the users timeline. If the latest activity is a retweet (marked by a leading 'RT' in the text), the text will be truncated to 140 characters. The full text of the original tweet is in the retweeted_status field of the JSON response. Hence, see under the latest_activity -> retweeted_status -> full_text field. last_active : Datetime of the latest activity according to the users timeline. liked_tweets : List of IDs of the liked tweets by the user. composed_tweets : List of IDs of the composed tweet by the user. favourites_count : The number of Tweets this user has liked in the account\u2019s lifetime. British spelling used in the field name for historical reasons. verified : When true, indicates that the user has a verified account. statuses_count : The number of Tweets (including retweets) issued by the user. status : Latest tweet object according to the user's timeline. contributors_enabled : Whether contributors are enabled for this account. profile_image_url_https : A HTTPS-based URL pointing to the user\u2019s profile image. profile_banner_url : The HTTPS-based URL pointing to the standard web representation of the user\u2019s uploaded profile banner. default_profile : When true, indicates that the user has not altered the theme or background of their user profile. default_profile_image : When true, indicates that the user has not uploaded their own profile image and a default image is used instead. withheld_in_countries : When present, indicates a list of uppercase two-letter country codes this content is withheld from. bot_scores : Estimation for bot-like behavior from the Botometer API .","title":"Literals user info"}]}
